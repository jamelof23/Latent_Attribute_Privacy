{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamelof23/Latent_Attribute_Privacy/blob/main/Empirical_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup + load InterfaceGAN generator (GPU) + boundaries + latent\n",
        "# ==== ENV & REPO ====\n",
        "import os, sys, io, cv2, numpy as np\n",
        "from PIL import Image\n",
        "import IPython.display as display\n",
        "\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'Latent_Attribute_Privacy'\n",
        "!git clone -q https://github.com/jamelof23/Latent_Attribute_Privacy $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}/models/interfacegan_official')\n",
        "!mkdir -p models/pretrain\n",
        "!wget -q https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O models/pretrain/stylegan_ffhq.pth\n",
        "\n",
        "# ==== IMPORTS ====\n",
        "from models.model_settings import MODEL_POOL\n",
        "from models.stylegan_generator import StyleGANGenerator\n",
        "from google.colab import files  # for auto-downloads\n",
        "\n",
        "def build_generator(model_name):\n",
        "    gan_type = MODEL_POOL[model_name]['gan_type']\n",
        "    assert gan_type == 'stylegan'\n",
        "    return StyleGANGenerator(model_name)\n",
        "\n",
        "model_name = \"stylegan_ffhq\"\n",
        "latent_space_type = \"W\"  # we work in W\n",
        "generator = build_generator(model_name)\n",
        "synthesis_kwargs = {'latent_space_type': 'W'}\n",
        "print(\"✅ Generator ready.\")\n",
        "\n",
        "# ==== BOUNDARIES: Age (target), Gender (non-target) ====\n",
        "# Put your .npy boundaries under: Latent_Attribute_Privacy/models/interfacegan_official/boundaries/\n",
        "# e.g. stylegan_ffhq_age_w_boundary.npy, stylegan_ffhq_gender_w_boundary.npy\n",
        "age_path    = 'boundaries/stylegan_ffhq_age_w_boundary.npy'\n",
        "gender_path = 'boundaries/stylegan_ffhq_gender_w_boundary.npy'\n",
        "assert os.path.exists(age_path) and os.path.exists(gender_path), \"Boundary npy files not found.\"\n",
        "\n",
        "b_age    = np.load(age_path).astype(np.float64).reshape(-1)\n",
        "b_gender = np.load(gender_path).astype(np.float64).reshape(-1)\n",
        "\n",
        "# Normalize\n",
        "b_age    /= (np.linalg.norm(b_age) + 1e-12)\n",
        "b_gender /= (np.linalg.norm(b_gender) + 1e-12)\n",
        "\n",
        "# ==== UPLOAD LATENT ====\n",
        "print(\"[INFO] Upload latent .npy (shape (1,512) or (512,))\")\n",
        "uploaded = files.upload()\n",
        "latent_path = list(uploaded.keys())[0]\n",
        "latent_codes = np.load(latent_path).astype(np.float64)\n",
        "if latent_codes.ndim == 2 and latent_codes.shape == (1,512):\n",
        "    w0 = latent_codes[0]\n",
        "elif latent_codes.ndim == 1 and latent_codes.shape[0] == 512:\n",
        "    w0 = latent_codes\n",
        "else:\n",
        "    raise ValueError(f\"Latent must be (1,512) or (512,), got {latent_codes.shape}\")\n",
        "\n",
        "# Quick preview synth\n",
        "def imshow(image, viz=256):\n",
        "    h, w, _ = image.shape\n",
        "    if (h,w)!=(viz,viz):\n",
        "        image = cv2.resize(image, (viz, viz))\n",
        "    buf = io.BytesIO(); Image.fromarray(image.astype(np.uint8)).save(buf,'jpeg')\n",
        "    display.display(display.Image(buf.getvalue()))\n",
        "\n",
        "x0 = generator.easy_synthesize(w0[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "print(\"Original latent image:\")\n",
        "imshow(x0)\n",
        "\n",
        "# Save & auto-download the original image\n",
        "orig_path = '/content/original.png'\n",
        "Image.fromarray(x0.astype(np.uint8)).save(orig_path)\n",
        "try:\n",
        "    files.download(orig_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped (Colab-only):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "bfBoSnicW0r6",
        "outputId": "cec96abf-1486-4bc1-8c1a-905274903fc1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Latent_Attribute_Privacy' already exists and is not an empty directory.\n",
            "✅ Generator ready.\n",
            "[INFO] Upload latent .npy (shape (1,512) or (512,))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51f9c02b-2424-41fa-ad05-5d2f542b8708\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51f9c02b-2424-41fa-ad05-5d2f542b8708\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 777.npy to 777 (5).npy\n",
            "Original latent image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAEAAQADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1sgUwinmmmuhmSEozSUVJQtLTc0uaAA1GxpxaszU9bs9LhMlxKB6Ad6ALU0ixoWdgqjqTXF6345tbUtDYgTydC38I/wAa5nxL4quNVdo4XaO3/u561yhck0Aat9rt7qEhaWU+wXgCs1pCT1J/Got2aKm4x2Sec0wsfWnYzSbKQxNxxRk9zRjFG0+tAC7sHrSiSmHI9Pypd2OwoAsRXUkbAo7D6Vtafrs0TASsWX3Nc7vHc0oJHRqaYmj0u1vYrmMMjDJ7Zp7yY7157ZajJbShlYjnoR1rrba9F1AHU5PcelUncm1jQMh9f1pA/vVTzDmnhjTAtbv85pcnH/16hVqfuoAR8nvUDZqZjUTUCGrmlJNJmgnigCCYnmmwgjOKWQ5p8XAoshHrhptONJQykJikxTjTWOKQxDxyaydS8QWOmsUklUyddgPNZfijxOumwtBBhpyOucBa8pu783EzOzMzsckk9aAOw1n4gXMheKzVY1z9/qa4y81G4u3LTyu5JzyaqSEsQQajJJGTSuA4tnqTTe1NLdRSE4pDHYzSZIpu73pQc9qAF30vzdQaAAKC3pSGIefrTdpHc04nimbj3oAXJBpct6frTck8Z4o2+5pAOOQOmR9KZuKfw8U4ZU/ezS+Z/eH5igBokbsfzq7YahJayhh+I9aqbUbp/OmmIKepHvimB3VtcR3UIkjOc9R6VYArj9LvnsrgBzujbrj0rsI2WRAyHKkZBq07kNWHipFpmKeKoQvao2FS0hFAEByKaTUxWo2Wk0JogIzUijC0beacRhaAPWaMUpFApFCGsbXdYg0mzaWVuTwoHUmtiQhVJzXlHjrUHkudnnh17IvQfWgZzGtai+oXjyngE8LnpWSSN2aJG5PNMGam47DwcGkYHPBpQM4FKOBQMgYGmgkHBqw65qF0INIBvQ07dTc46igEelFwFwc0AntRwRjoabnB5oAfg0H3oVgeKXGDQAmzPOaACp5NPXj6U4qCOKBEfXvg+9NYlT8wIHqORTj7g4pASOD8y0DG7SRlCD7UqSsvBz9KCndDil3Z+8OR19aAHqx7f/WrpNBv90Zt2Putc0BjBB696uWsjRTq68MDmnHRiZ2okGKPMrOF1uQN60Cckda1MzSEtL5nvWes3vTxLnvSAvB6ODVZJPerMfzUDEC0j/dqYjAqvLwDQB64RxSU402pGZ2s3X2TTpZuPlUnmvCNVv5b68klkbOTxXq/xAmlj0RwkuxScEd29q8ZkOTzSY0MIpelJmk96koeOKfjke9IoBGKcBzigB4TPFNaM96nhQt2qyLY7irDntUORoomW1ueoqIxFTnFbUVr+82MOKlk0zqaXMPkOeKE896b14YfjWy1gVbBWonsOOKfMLkZmAYNSDpz0qy1oy8UwQsDkj61V0S4sjxj6GnqBn2NLswdp79KFypwelMVhWjDGotmCRirBHAYfQ0oXeM9x+tFwsVNpHI/Ggg8MO1Wni2sOOtRtGRQFiMAdPWpIiePY0jKdgI7Uqj5qaJNaCQ+UBnOKkEmKpWzfeXPvU5NWQyysvNSrITVJW5qxEcmmI0oOcVpQpxVC1XOK2Ik4FA0RsnFU5R1rVdMJWXPwxpAeuGkNOpDQM4P4kRF9KRxIV2tnaO9eQOecd69u8fRGXQJQCc9QF714hJwSKllIb1py8CmDrUqDOKgoeOnvUsSFm9qI481dgiyAAOaTZUUTW0BWRdw4atM2e9FP8QqWG2MsCnHzAVoQRb1GRyKwcjojEzBaliOCHHr3q9Dbb15HWrjwg7GA5Bq/b2uUBAqeYtRMV9Oz2qvJphAyFrq/s4PGKU2alcYo5h8pxM2m5BIWsyeyK54Negy2K4PFYt/p+ASBVKRLgcTMnyfSoyCwB79617uzMZY468gVmqoVj6VqmYSiNiUMGWpoVX5fdqYibdx9DUkK5jUju3FVcVie5gyVOOtJPabY1IHWtL7K0hjBHGa0I7ESOoxwM1HNYvluck8JWM8VXJw9dRqun+XESormJFw30q4yuZTjYmhbDj3qzniq0GA2CKsVstjFjlPNWoPvCqg61bgHzCgk2bIZxW5AvArFsV6Vv268UxoJV+SsS5+8a3rnhDXP3J+c0Az2DHFIRTu1IaQHP8Ai6BpdAudnXae1eAy/fIIr6L12JpdHuVTG7YcZ6V873QIuJAeoJzUy2KiRKOasRDmoEq1EMcmszRIsxLzgVr2NruO41SsoScHGSa6ixs8ICRWUpG8IlixgwoGK0FtcHgURx7WBrQjXOKxZsiktoM8itGCIBQKesJParMUZHakURLb5PSpBb+1W0ULUgAIyKdguZ7WvHIrOvLHKnA610e0MOlQyQq2QaAucBqGmF4iNvNc2+nsoII+bORXq81gjqRisabw+kznjg1SZLimebyQERFVBOTitnTtHbyU3oSzfpXZxeG7cOrbRhegxWtBpkcZztquZi5Ejl49LIVSV5FXbXTwm7I610bWi44GKYbcAcCpbY7I5XU7DfC4xXnd3B5d0Ux3r2S5tgyEEda8u8T25s9TzjgnNaU3rYyqrS5lWwBYZHarBGDUUOPM4qVjzXXHY4pbiDrVy3GSKqL1q7bDmmSbdiOldBbL8orCsR0robYfLQNEV4MJXOXR+c10d9whrmLs/OaAZ7PSUvaikBDcRiS3kRhkFSCPWvnrxLaCz1q5iCCMBs7Ac49q+iX+4fpXgfjaF4fEc4dAgY5XvketTLYqO5gRDJFX4Y8sBVOLANa+np5kqj8axkzaKNzSdP3YYjk108FuEQDFQ6VAogU960yoFc7Z1RRXK4HHarcTKibmNVJZEjRsmsHUdYA/diQJGOMk4z+NNK4N2Op/tSBCehA6nNC6/Z5wXWvPnv4JDiTUI0X0U5pUbTpeBqaD1ya05EjNzO+bxPpynBmFW7fXLGbhJ1J+tectbWJG5dStifQyAZ/OmraEgGG4RwOhRwcUnFDUz1IXsbfdcH8aXzwx61wNldTIVDMcjr710lpdblHPNZvQ1i7m00ox1qEzAHtioGkO3PWsPU9RkiRthOegxQtSnodA+p2tsuZZFXHqaz5/GVhCcKQ/pjvXC3HmytvuLhIlP8Uj4A+lJBHprPt+0S3DDgiGJmH6CtlGxhKZ2P8AwnNu7YEZzVlPEqSHmNga56C0twoKaRfuD/0zRf5sKuRx+WuF0TUjjoSYuP8Ax+k0hJnU215DexgoQQa4j4iWAW3guUH3WwTV4Xv2WXcNP1KA9TiEOPx2k1n+JNdsNX017WG4VZxg7JAU5/GlFNO45STVjiYWDEMpqyaqC2uLaVRJGQG6HqDVzHFdUdjimtRUHNXrZeRVRRV+2XkVZBuWQxit+2+7WFZjpW9bfdpFIrX/AN01y939811N+Mqa5a7HzmmJntNFHaikA1/umvGPiLZCXU1vIN8gK4YgZUY9K9R8T3bWehzujYZsLn6nn9M15fJrSSs0M0RK5wDWNWpyvlOijRc05HERSYODW3Z3MFuN7SKCOw60zU7KInMCbecnHeqenaf599HFICQe1Z3TRXK4s7K08S20UKqpyffii+8WpGmIuWwc8cZqxZ6FZRKP9HU/Xmr50yycbWtISPQoKzvHsbuM2tzzyfxVql64iEgXecDYOa3dP8M2zKs1+8k8p5bc3Gar6zoEGn+KNLa2TbFcucoOgYc8VuXGm37Bts4Vfp0pylppoTCF782pNHFo2nJ/x7wJjuVFSJ4g0tTiPyzjsq1hf8IrPdyZkuS/1aph4GdfuTOue4IqNHuy/eWyNdvElg4I8pCPXbms26k0u9JYW8Jb1CjNQf8ACISWyuS+8t/eNZMmkXlrNlGDL6Bqei2Ynd7otMpif/RLmSIjorHcv5Grun+LoLOU2+pqYZB/GoypHr61BBZAZd2JPp6VzmrwG91+2tEHLLzgds1atLRku8VdHo8ni3R1g3/bIyuOzAn8s5rm21SXX7+SO1kMFqnWQD52+npTP+EIs1thI4vF46lhj+VO8L6eYbzULUNuaMIwI/iBzzSslqhvmdlI1rbStKtx50kIlk7yTHcT+dXU1myhIjXHoAorNvbK6mk8vlYh1weTWTL4Wv57gS2zEJ2yxBqbc27K+H4UdjF4jsw20ON3cZFaEWt20owJQCfWuP0/wXfNMJLx0YBdoGf61LceFJLeQtDf7P8AZ6ik1FdQUpPdHUT3WTuRh+FcN4whkmie6MYKxSDEg64I6fnW7b29xHGFZzI3rjFM8RQFfCd9JJjhFP47hVU3ZkVF7pyGkaPqP2cajgG0ZTlS/JHripWGCa17OSaO0gtTxE1uP5VjucufY10UqnNddjCvR9nyvuhy9a0LUc1mqeRWnackVucxtWnUVv233aw7NeRW9AMLQUitffdNctdj5zXU3/3DXLXZ+c0hM9n7UUgNKKBmD4xgefw9Ns5KFWx7Z5ry6CyZ2kzyTXtV3AtzayQv911Kn8a8xa2NnJOrjDKSpHvXNXWqZ14aXuuJzDQOJTHIOB39asaVbbdWDEcAGn3s7SMI0QFyeDWhp9u3yMww3esUzWSOkhjGwVJsBNEWAoFPNQUc74qTy7zQ7gn5UvVQ/wDAgRXTPb+YgOODWL4ptHu/Dl2Iv9dEvnR/7yHcP5Vu6Pdx6hpdrdxkFJoww9sjpQxx3M6fSJPvQsVP6VUa31iPhSprsl24xgUGND2osXc4OSx1mc/MBj1JqaLQpODO+5vQCu18qLHNQSKmMKKAuchfWQgtWZVxgc1ieC9PXUfE+oahIuY4SIYz1GRwSPyrp/Elwtjpk0r8EjEY7s56CrHhDSBpWkQwn/WP88h/2jVRfumbV5eh0ZtopLbYyAgjvXDWenrpfxB8ok+Xd2zCMerKcn9B+teiIo2VyvjDTria1h1HT/8Aj+sJBPGuPvgfeX8R/KmuwpbGncaPBcr8wIbsw61myaPdwcQz5H+0K19H1i21nTIr22YFXHzLnlG7g1fLq3UVLVilI5BoNSztLce1TQae7HMvJrpiiHtTdqA9OaVirmamnqVAAAFcr48jeHw8bKIZe7njhUe5b/61d4ZFUEkgCuTuFTxJ4pszA3mWGmsZZZB91pv4VB7kdTVwVncyqO65TI1y2XTbbf02R7B/KuOVuM12/wAQ0K2tswyAz4P5Vww7V1UY2jc5cRNyaT6EqHmtWyBJFZSda2NPXJFbI5zoLJeRW1GMLWXZL0rWUYFAyhqB+Q1y93/rDXTagflNcvdH5zQDPaAacKYKcKkY6uP8V6dtmS5jXiThwPUf5/SuwqhrNq13pkqR/wCsX5l+oqKivE0py5ZJnmtlZR/bMyjB7A+taSRKkv4nFXI41aMO0I39CcdKqNvV/myOeK4zuepaVvmqYDIqmrd6sxvxSBE6puGD07iufh0fWvD8kn9izRT2TMWFrNxsz2U10KOM1YWTAzRexVkzAXxTqlvxeaFOuP4omDZpJPHUEY/eadfr9Yv/AK9dA8ykEkDP0rF1a9hSFsheBRcdvMzZviJZqOLS7z2BUD+tRxeMtTv222GkMWPRpCcf0rJVHui0u3anbir3hy+EF28cz/dbIHtTduxNm+pq23hzU9RvIr/WZhI0fMcC/dSushUx44wBUY1q1EWA4zVT+2I3kwCKV7jUWjoImyOtRTJuqvbXaMucinT6hFHyzACmFmclf+F7uzu59R0C7ks5n5kiAzG5/wB01jReLfEImaFjYs6nB3RMDn/vqvQxqds6HEiniuK1a1hm1CS6gUZzzjvRzAoLsPTW/FMq/LFYAeux/wD4qpF/4Sq6GGvreAH/AJ5w5P6k0yyv9pCNxjtW9bXSuBzRzMXIijb+HXugBqt9c3a90aTan5LjP410tpa29lbLDbxJFGo4VBgCqyyLxU6y5FHM2LlS2OO+Iozptt/12/oa8+U16F8QedNtcf8APX+hrzsHmuyj8Bw1/jJ0PNbem8kVgxnmt7TOorZGJ1NkvStM8LWfZDgVouPkoAx9QbrXOXHLGt6/bk1gTH5jQwPZ6cKbSioKH0CkooA5m+jFvqMqYwpO4fjWNqDAuMdK6vWLBrqMTQjMqDGP7wrk7y3uUTfLC6qDjJFcc4OLO6nUUo+ZDG3FTB8CqqdKlByKg0LSyjNTCfArN3FTTWmbFJlJlq6u9in5q5x9+oXRyf3YPI9anvZmYbeeaks4SAOaaQXLlvaRhOQPpWdqekI7ebCTHIO61swr6E1K1qHPLUwvc4W4t9Sxs+0FfcVDb3Gp6dJ+8czR/wC11ruJdKV+dy/nUX9lKwwcUtAtIyIPEzhcAPmiaa/1UbTM0Mf+z1Nan9hANkeXVmOwSL7zrRdAlIwLbSbmF8fa5mX0LV0EUG2EKatRwxZGGBqZ402cEUhnO3lqQd8fDClsdRIO1shhwQa0ZVUkjPNZNxbAy7l4b1FIDfivSQDmr0NwW71zEMjLwTWpaSHjmgTKXjx86TbH/pv/AOymvPia7bxxcZsbSLuZC35D/wCvXD120vgOCv8AGTRda39MPIrAiHIrf0scitkYHW2PQVoTcRmqNgvSr9zxFTA5zUG61gzNya2dQPWsCZ8E0mB7gKUU3NOFSUOopKWgArP1a3Fxp0yY525H1FaFRsAQQe9Jq6sNOzueb7sGnK/NN1JPsuoTw4wFc4+naoo3zXFJWO+LuiyRmkKClByKUDuahlopzWrMNwqnNqQtTtYYxW6FDJWVqeirqELAHZIOjCmmDMiTxYI22xLuI4zUS+I7y5Pyq2PaqFl4dmtNSIuiCu4FWPTrXeWfhuAW0xjA5O5aJMcXbc5uLUdTdSyxSFfpViPU9RHWCX67a7/+x4rfTIhEi7wBuHrWiNHt/IC+WAR39aVyvaRPN01O9kbasMpb/dNNkn1NmK/Z2B969HtdJhRCzxjc2fwpp0mI+aSRuzgflRdh7WJ5c95qMAJZSPoarHxg9tJ5czc9816HqGlWUVqrOQzdTnoTXmGqaKdY1J2hQLFnl8VUNdwlO691G1b60l8QVPWtBQ7MCRnNVdJ0CKwhUYyR3NbCoEGO9SyV5kAh6etXYE24zUagZpZbhYY2diAqjJNCE2cp4yufN1GKAHiJOfqf8iucHWrV7cNeXs1w3V2z9B2qADmu6CsrHnTlzSbJ4RyK6LS15FYNuvIrpdMXpWpB1FgvAqxeHERqOxGFFPvPuUDOW1E9a564BANdLfJknisWeIHIpMVj2cGnA1AHp4akMmzRmmBqN1AD803qaTNZmta7a6HZG4uCSf4VXqTQBy/i+EQaosg6Spk/Ucf4ViwyciobnxI3iSSSYx7BEdqrntUMcmDiuWotWdlN6I2434qXdmsyOftmrCy5rFo2TNBG7VLt+XIFVYXBq4hzUlIpThM4dQVNTWqzxf8AHvPlD1Ru1STwB0II4NZJaWzlIDHaTxVLU0jJLRnQLqeoAbJI8gdGUdatf8JRIsGDaybh1FYkOqYA3VY/tqIDDH9KXKU4U5dDTXxGygAwks3OAen1qM6vcyO/yNtYcbV6VUGtW+Oo/wC+ajfWI3GFb8hRygqcexG9ncTQFbybKZyFz0pkFtEpCqBtHQCmSXpkbA5JqzbqTzT2FOXRErqqrgCqrDJqzLxxVZjikZMY7hBXN6/qOV+yo3Lcv9PStHU75baFm/i6AeprjpZGlkZ3OWJyTW1KF/eZzV6llyobilUc0U5K6kcRbtxyK6XTV6VzlvwRXS6b0FWNHT2fCCluuVNMtT8op1xjaaTKRgXuBnNYFw4ySDWnqUjeZgHisKdwzkBuB1NS2B7AkwLdanEtYAu8EYNW4rvdjms+ezM1I2BJkU8NVOOUEdalDin7RFXJy3FcL46ie70+VlGQnSuylk2xnHWsi/txcWcsZGdwNaw1Bs8e8MyET3MTdwDW44KnIrDtImsfEM8LDB5FdDjeua5amkjrp6xI47jNW4rj1rKnRkbctMjuuxNRa5pex0kU/PWtS3lDY5rlobngc1o215twM1LiWpHUxqsi4NV7rTd6nAzUNrd9DmtiGdXXms2jRO5ys2mSZwNyn6VSk0m9Y/JI35V36pE/UCpBBEOgFF2Gh5yukaj6n8qtW+i32fnOBXeeRH2ApfJQdhRdgcxbaUyEbhk1pCAQpjvWm8aqM8Cs+6kVQaAKE2BWbe3KQRszHAFT3VyqKWJxjvXH6nfPcykchB0Fa06fM/Iwq1FBeZU1C8e6mLseB90elUd1PkqAnmuq6Ssjid3qyXdUqGqoapozQmTY0ID8wrpdMbgVzEB5FdDprcitEwR1VqflFNvX2oT7Uls3y1V1GQlCKGUjm9TmB3BfTrWNO58p0POOf5Vo3AOSDzWXcZ3Rx4AzwW9TUSHod9vPHNWYHII5qGOLeBV22tuRxXG5OT0OZJtl2F2IqwrNu5zTUUIMAU7mrjTd9TZQHs24VEVzxUqjIp23FdcdCmjzjxjoRtNQi1WFD5bHbLjt6Gq9sdyj3r0u5to7q2eKVQyOMEHuK4C+0t9Iu/L5aBj+7Y+nofesa0ftGtCXQpXMHBIHFZE8RByK6VQHXNUbyxPLoMjuK50zqauYSXDRtg1cjuz1BqvPb5+tVgWjODVJkHS2ep4wrnFbdvqQx96uFV896sx3UsfQkik0mNSaPRIdSXAyf1q4L/K8GvOY9UdOpNW01xl71PIzRTR3gv8AsTUq6gmOWrgv7cJ703+2pO2aORhzo7e51JADzWLPemZyF5rCW8nuW5JC1pWsZotYL32KtzIZ2ljU5aLAcfXvWNcW/J45qOHUHTUbmZWzidgR7ZrZvIA8ccyD5JBkf4VtJuMLo86ve9zm5oto6VSYc1uXEHGMVmPAwbpUwncmDuVAOanjFPW3YnpVqK0bNaqSLHW69K3tOGCKz4LU8cVsWcJUirU0TY3bc/JVTUBlTVqDhcVBdDINXcqxzV0vesK+3GQFSQR6V014nymsC4iyxqXqF7HqUVuFxxVpUC9BTzj+EUDI/hNTZISsOC0YpcnH3TSZb+6aLlD04qQDNMUexp2do6VSYgPGRVC/s47yBopVyp7+nvV3ceuDRgSDKg/lWlroi9mcFNay2FyYJf8AgLdmFO2giuu1HTkvLco6kMOVcDlTXKGKSGRopFwynFcNWnys7qVTmWpn3Vir5ZRg1kz2JGciup8vcOlQyWu7+Gs07GjVzj2tyhxjFIMqa6WXTt2flOPpVCbSn7cfhVcxPKZwKkc05Y0JqV9OlU85/KhLCTP3v0pXHYcsKVPHEpPAqaCxbjNadvp7YHHH0ouFiKztdzAYra8gQxEkcAVZsrIIoO05+lJrH7nTpmxjCHt7Ur3ZS0PKdNfzrq5BPDSMc/jXcaKvn2LWcn31G5CfWuI0VQsTv3LV2OlSFHSQDkV2JK1mcUlzaCSWu4nI5qk9lz0rqNQhyq3KDh+GHo1ZR57V581KErHJrF2MkW4B6VYjiHpU7jntTc4o52aqVyaJBxV+EAVnJJjvViOY0RqNFJmtG4ApkzBhVRJzihpSRXRGsO5Uu0Bzisp7bcxrXkO6oljyc4olWsI//9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ba5c96ba-fcec-4b4e-9052-6f10cbb03309\", \"original.png\", 1154322)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SUBSPACE S from boundaries (Age target; can add more cols for joint case) ====\n",
        "# For single-attribute Age: N = [b_age]; for joint add more columns, e.g., np.stack([b_age, b_smile, ...], 1)\n",
        "\n",
        "# (A) Orthogonalize Age against Gender to reduce leakage\n",
        "def cosine(u, v):\n",
        "    return float(np.dot(u, v) / ((np.linalg.norm(u)+1e-12)*(np.linalg.norm(v)+1e-12)))\n",
        "\n",
        "print(f\"[diag] cos(angle(age, gender)) BEFORE = {cosine(b_age, b_gender):.4f}\")\n",
        "b_age_orth = b_age - (np.dot(b_age, b_gender)) * b_gender\n",
        "b_age_orth /= (np.linalg.norm(b_age_orth) + 1e-12)\n",
        "print(f\"[diag] cos(angle(age_orth, gender)) AFTER  = {cosine(b_age_orth, b_gender):.4e}\")\n",
        "\n",
        "# Use the orthogonalized Age for the subspace\n",
        "N = b_age_orth[:,None]  # d x k ; here k=1\n",
        "\n",
        "# Orthonormalize N -> Q_S (Gram–Schmidt via QR)\n",
        "Q, _ = np.linalg.qr(N)  # d x k, columns orthonormal\n",
        "k = Q.shape[1]\n",
        "d = Q.shape[0]\n",
        "print(f\"Subspace dim k={k}, ambient d={d}\")\n",
        "\n",
        "# Projector Pi_S = Q Q^T (we'll use Q directly for sampling)\n",
        "# Pi_S = Q @ Q.T  # not needed explicitly for sampling\n",
        "\n",
        "# ==== Reference edit (temporary) ====\n",
        "alpha_init = 2.0  # initial guess (not final)\n",
        "w_tmp = w0 + alpha_init * b_age_orth\n",
        "x_tmp = generator.easy_synthesize(w_tmp[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "Image.fromarray(x_tmp.astype(np.uint8)).save('/content/ref_alpha_init.png')\n",
        "\n",
        "# ==== CLIP scorer f_S  (public attribute scorer) ====\n",
        "!pip -q install open_clip_torch ftfy regex\n",
        "import torch, open_clip\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "clip_model, clip_preprocess, _ = open_clip.create_model_and_transforms(\n",
        "    'ViT-B-16', pretrained='laion2b_s34b_b88k', device=device)\n",
        "clip_model = clip_model.to(device)\n",
        "clip_model.eval()\n",
        "clip_tokenizer = open_clip.get_tokenizer('ViT-B-16')\n",
        "\n",
        "# Prompts (face-specific helps stability)\n",
        "texts_age    = clip_tokenizer([\"a young adult face, portrait\", \"an elderly face, portrait\"]).to(device)\n",
        "texts_gender = clip_tokenizer([\"a portrait photo of a male face\", \"a portrait photo of a female face\"]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    text_emb_age    = clip_model.encode_text(texts_age);    text_emb_age    /= text_emb_age.norm(dim=-1, keepdim=True)\n",
        "    text_emb_gender = clip_model.encode_text(texts_gender); text_emb_gender /= text_emb_gender.norm(dim=-1, keepdim=True)\n",
        "\n",
        "def _prep_batch(np_batch):\n",
        "    ims = [Image.fromarray(img.astype(np.uint8)) for img in np_batch]\n",
        "    ims = torch.stack([clip_preprocess(im) for im in ims]).to(device)\n",
        "    return ims\n",
        "\n",
        "@torch.no_grad()\n",
        "def clip_scores(np_batch):\n",
        "    \"\"\"\n",
        "    Returns dict with COSINE scores (no logit_scale) for age (old-young) and gender (woman-man).\n",
        "    Each entry shape: [batch]\n",
        "    \"\"\"\n",
        "    ims = _prep_batch(np_batch)\n",
        "    img_emb = clip_model.encode_image(ims); img_emb /= img_emb.norm(dim=-1, keepdim=True)\n",
        "    logits_age    = (img_emb @ text_emb_age.T)      # [B,2] cosine\n",
        "    logits_gender = (img_emb @ text_emb_gender.T)   # [B,2] cosine\n",
        "    age_score    = (logits_age[:,1] - logits_age[:,0]).detach().cpu().numpy()       # old - young\n",
        "    gender_score = (logits_gender[:,1] - logits_gender[:,0]).detach().cpu().numpy() # woman - man\n",
        "    return {'age': age_score, 'gender': gender_score}\n",
        "\n",
        "# Re-center w_ref near CLIP age boundary (score ≈ 0)\n",
        "def line_search_alpha_to_score0(w0, v, a_min=-5.0, a_max=5.0, steps=201):\n",
        "    alphas = np.linspace(a_min, a_max, steps)\n",
        "    lat_batch = w0[None,:] + alphas[:,None] * v[None,:]\n",
        "    bs = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    imgs_list = []\n",
        "    for s in range(0, steps, bs):\n",
        "        imgs_list.append(generator.easy_synthesize(lat_batch[s:s+bs], **synthesis_kwargs)['image'])\n",
        "    imgs = np.concatenate(imgs_list, axis=0)\n",
        "    scores = clip_scores(imgs)['age']  # >0 older, <0 younger\n",
        "    idx = int(np.argmin(np.abs(scores)))\n",
        "    return float(alphas[idx]), float(scores[idx]), alphas, scores\n",
        "\n",
        "def find_bracket_for_zero(alphas, scores):\n",
        "    # Find consecutive indices with sign change\n",
        "    for i in range(len(alphas)-1):\n",
        "        if np.sign(scores[i]) == 0:\n",
        "            return alphas[i], alphas[i]\n",
        "        if np.sign(scores[i]) != np.sign(scores[i+1]):\n",
        "            return alphas[i], alphas[i+1]\n",
        "    return None\n",
        "\n",
        "def refine_alpha_bisection(w0, v, a_lo, a_hi, scorer_fn, iters=14):\n",
        "    alo, ahi = float(a_lo), float(a_hi)\n",
        "    # if degenerate bracket (exact zero), return\n",
        "    if alo == ahi:\n",
        "        x_mid = generator.easy_synthesize((w0 + alo*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "        s_mid = scorer_fn([x_mid])['age'][0]\n",
        "        return alo, s_mid\n",
        "    # ensure opposite signs\n",
        "    x_lo = generator.easy_synthesize((w0 + alo*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "    x_hi = generator.easy_synthesize((w0 + ahi*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "    s_lo = scorer_fn([x_lo])['age'][0]\n",
        "    s_hi = scorer_fn([x_hi])['age'][0]\n",
        "    if np.sign(s_lo) == np.sign(s_hi):\n",
        "        # fallback: return the closer-to-zero endpoint\n",
        "        if abs(s_lo) <= abs(s_hi): return alo, s_lo\n",
        "        else: return ahi, s_hi\n",
        "    for _ in range(iters):\n",
        "        amid = 0.5*(alo+ahi)\n",
        "        x_mid = generator.easy_synthesize((w0 + amid*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "        s_mid = scorer_fn([x_mid])['age'][0]\n",
        "        if s_mid == 0: return amid, s_mid\n",
        "        if np.sign(s_mid) == np.sign(s_lo):\n",
        "            alo, s_lo = amid, s_mid\n",
        "        else:\n",
        "            ahi, s_hi = amid, s_mid\n",
        "    return amid, s_mid\n",
        "\n",
        "alpha_star0, score0, alphas_scan, scores_scan = line_search_alpha_to_score0(w0, b_age_orth, -5.0, 5.0, 201)\n",
        "br = find_bracket_for_zero(alphas_scan, scores_scan)\n",
        "if br is not None:\n",
        "    alpha_star, score_at_alpha = refine_alpha_bisection(w0, b_age_orth, br[0], br[1], clip_scores, iters=14)\n",
        "else:\n",
        "    alpha_star, score_at_alpha = alpha_star0, score0\n",
        "\n",
        "print(f\"[anchor refined] α ≈ {alpha_star:.4f}  score ≈ {score_at_alpha:.4e}\")\n",
        "\n",
        "w_ref = (w0 + alpha_star * b_age_orth).astype(np.float64)\n",
        "x_ref = generator.easy_synthesize(w_ref[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "Image.fromarray(x_ref.astype(np.uint8)).save('/content/ref_recentered.png')\n",
        "print(\"Reference (re-centered) image:\")\n",
        "imshow(x_ref)\n",
        "\n",
        "# Auto-download reference images\n",
        "for p in ['/content/ref_alpha_init.png', '/content/ref_recentered.png']:\n",
        "    try: files.download(p)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "vbnXi7qRW8lV",
        "outputId": "30a747ff-809d-43a3-8b0e-80d32209f4bb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[diag] cos(angle(age, gender)) BEFORE = 0.0706\n",
            "[diag] cos(angle(age_orth, gender)) AFTER  = 1.4156e-13\n",
            "Subspace dim k=1, ambient d=512\n",
            "[anchor refined] α ≈ 4.7500  score ≈ -9.7520e-03\n",
            "Reference (re-centered) image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f26de2b-b704-4305-a22d-e88d799ba70b\", \"ref_alpha_init.png\", 1239898)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81c6f008-0f2d-4d0b-8086-e9eb47a27faa\", \"ref_recentered.png\", 1395588)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate L_s by finite differences\n",
        "# ==============================\n",
        "# L_S ESTIMATION (central diff, chunked)\n",
        "# ==============================\n",
        "import numpy as np\n",
        "\n",
        "def estimate_Ls_central_diff_chunked(\n",
        "    w_ref: np.ndarray,\n",
        "    Q: np.ndarray,\n",
        "    scorer_fn,                 # callable: np_batch[H,W,3] -> np.array shape [B] or [B,m]\n",
        "    h: float = 0.05,\n",
        "    num_dirs: int = 32,\n",
        "    seed: int = 42,\n",
        "    batch_size: int = None,    # override; if None, use generator.batch_size or 4\n",
        "    vector_norm_axis: int = -1 # if scorer returns [B,m], take L2 along this axis\n",
        "):\n",
        "    \"\"\"\n",
        "    Estimates ||J_f(w_ref) Q||_2 using central differences along random unit vectors v in R^k:\n",
        "        ||J_f Q||_2 ≈ max_v || f(w_ref + h Q v) - f(w_ref - h Q v) || / (2h)\n",
        "    \"\"\"\n",
        "    assert Q.ndim == 2, \"Q must be (d,k)\"\n",
        "    d, k = Q.shape\n",
        "    assert w_ref.shape[0] == d, f\"w_ref shape {w_ref.shape} not compatible with Q (d={d})\"\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dirs = rng.normal(size=(num_dirs, k))\n",
        "    dirs /= (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "    bs_default = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    bs = int(batch_size) if batch_size is not None else bs_default\n",
        "\n",
        "    deriv_all = []\n",
        "    for start in range(0, num_dirs, bs):\n",
        "        vblock = dirs[start:start+bs]\n",
        "        lat_plus  = []\n",
        "        lat_minus = []\n",
        "        for v in vblock:\n",
        "            dv = (Q @ v).astype(np.float64)\n",
        "            lat_plus.append (w_ref + h*dv)\n",
        "            lat_minus.append(w_ref - h*dv)\n",
        "        lat_plus  = np.stack(lat_plus,  axis=0)\n",
        "        lat_minus = np.stack(lat_minus, axis=0)\n",
        "\n",
        "        imgs_plus  = generator.easy_synthesize(lat_plus,  **synthesis_kwargs)['image']\n",
        "        imgs_minus = generator.easy_synthesize(lat_minus, **synthesis_kwargs)['image']\n",
        "\n",
        "        s_plus  = scorer_fn(imgs_plus)\n",
        "        s_minus = scorer_fn(imgs_minus)\n",
        "\n",
        "        s_plus  = np.asarray(s_plus)\n",
        "        s_minus = np.asarray(s_minus)\n",
        "\n",
        "        if s_plus.ndim == 1:\n",
        "            deriv_blk = np.abs(s_plus - s_minus) / (2*h)\n",
        "        elif s_plus.ndim == 2:\n",
        "            diff = s_plus - s_minus\n",
        "            deriv_blk = np.linalg.norm(diff, axis=vector_norm_axis) / (2*h)\n",
        "        else:\n",
        "            raise ValueError(f\"scorer_fn must return [B] or [B,m], got shape {s_plus.shape}\")\n",
        "\n",
        "        deriv_all.append(deriv_blk)\n",
        "\n",
        "    deriv = np.concatenate(deriv_all, axis=0)\n",
        "    Ls_hat = float(np.max(deriv))\n",
        "    return Ls_hat, deriv\n",
        "\n",
        "# Ambient (R^d) Lipschitz estimate for isotropic DP baseline\n",
        "def estimate_L_full_central_diff(\n",
        "    w_ref, h=0.05, num_dirs=32, seed=0, batch_size=None, scorer_fn=lambda imgs: clip_scores(imgs)['age']):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    d = w_ref.shape[0]\n",
        "    dirs = rng.normal(size=(num_dirs, d))\n",
        "    dirs /= (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "    bs_default = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    bs = bs_default if batch_size is None else int(batch_size)\n",
        "    deriv_all = []\n",
        "    for start in range(0, num_dirs, bs):\n",
        "        ublk = dirs[start:start+bs]\n",
        "        lat_plus  = w_ref[None,:] + h*ublk\n",
        "        lat_minus = w_ref[None,:] - h*ublk\n",
        "        imgs_p = generator.easy_synthesize(lat_plus,  **synthesis_kwargs)['image']\n",
        "        imgs_m = generator.easy_synthesize(lat_minus, **synthesis_kwargs)['image']\n",
        "        s_p = np.asarray(scorer_fn(imgs_p))\n",
        "        s_m = np.asarray(scorer_fn(imgs_m))\n",
        "        deriv_all.append(np.abs(s_p - s_m)/(2*h))\n",
        "    deriv = np.concatenate(deriv_all, axis=0)\n",
        "    return float(np.max(deriv)), deriv\n",
        "\n",
        "# Convenience wrappers for current CLIP setup\n",
        "def clip_age_scalar(np_batch):     return clip_scores(np_batch)['age']\n",
        "def clip_age_gender_vector(np_batch):\n",
        "    s = clip_scores(np_batch)\n",
        "    return np.stack([s['age'], s['gender']], axis=1)\n",
        "\n",
        "# Estimate subspace and ambient Lipschitz (with safety margin)\n",
        "Ls_hat, _      = estimate_Ls_central_diff_chunked(w_ref=w_ref, Q=Q, scorer_fn=clip_age_scalar, h=0.05, num_dirs=32, seed=42)\n",
        "Lfull_hat, _   = estimate_L_full_central_diff(w_ref, h=0.05, num_dirs=32, seed=123)\n",
        "\n",
        "SAFETY = 1.25\n",
        "Ls_est_safe   = Ls_hat   * SAFETY\n",
        "Lfull_est_safe= Lfull_hat* SAFETY\n",
        "\n",
        "C_sub = Ls_est_safe    * np.sqrt(2.0 * np.log(1.25/1e-5))\n",
        "C_iso = Lfull_est_safe * np.sqrt(2.0 * np.log(1.25/1e-5))\n",
        "\n",
        "print(f\"L_S estimate @w_ref: {Ls_hat:.4f}   (with safety → {Ls_est_safe:.4f})\")\n",
        "print(f\"L_full estimate @w_ref: {Lfull_hat:.4f}   (with safety → {Lfull_est_safe:.4f})\")\n",
        "print(f\"[calibration] C_sub = {C_sub:.4f}   C_iso = {C_iso:.4f}   (δ=1e-5)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5AUpVOnW9cm",
        "outputId": "c09ab01f-9002-4768-efc8-c5797a65a47c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L_S estimate @w_ref: 0.2435   (with safety → 0.3044)\n",
            "L_full estimate @w_ref: 0.1883   (with safety → 0.2354)\n",
            "[calibration] C_sub = 1.4747   C_iso = 1.1406   (δ=1e-5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === C2: Ambient Lipschitz L_full estimation (robust) & fairness floor ===\n",
        "import numpy as np\n",
        "\n",
        "def estimate_Lfull_ambient_cdiff(\n",
        "    w_ref: np.ndarray,\n",
        "    h: float = 0.05,\n",
        "    num_dirs: int = 128,     # more ambient directions → stronger bound\n",
        "    seed: int = 7,\n",
        "    scorer_fn=None,          # default uses age+gender vector\n",
        "    batch_size: int = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Estimates ||J_f(w_ref)||_2 via central differences along random unit vectors in R^d:\n",
        "        ≈ max_v || f(w_ref + h v) - f(w_ref - h v) ||_2 / (2h)\n",
        "    \"\"\"\n",
        "    assert w_ref.ndim == 1\n",
        "    d = w_ref.shape[0]\n",
        "    if scorer_fn is None:\n",
        "        scorer_fn = clip_age_gender_vector  # vector scorer: [age, gender]\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dirs = rng.normal(size=(num_dirs, d))\n",
        "    dirs /= (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "    bs_default = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    bs = int(batch_size) if batch_size is not None else bs_default\n",
        "\n",
        "    deriv_all = []\n",
        "    for start in range(0, num_dirs, bs):\n",
        "        vblock = dirs[start:start+bs]               # [b,d]\n",
        "        lat_plus  = w_ref[None,:] + h * vblock\n",
        "        lat_minus = w_ref[None,:] - h * vblock\n",
        "\n",
        "        imgs_plus  = generator.easy_synthesize(lat_plus,  **synthesis_kwargs)['image']\n",
        "        imgs_minus = generator.easy_synthesize(lat_minus, **synthesis_kwargs)['image']\n",
        "\n",
        "        s_plus  = np.asarray(scorer_fn(imgs_plus))   # [b,m] or [b]\n",
        "        s_minus = np.asarray(scorer_fn(imgs_minus))\n",
        "\n",
        "        if s_plus.ndim == 1:\n",
        "            deriv_blk = np.abs(s_plus - s_minus) / (2*h)                 # [b]\n",
        "        else:\n",
        "            diff = s_plus - s_minus                                      # [b,m]\n",
        "            deriv_blk = np.linalg.norm(diff, axis=-1) / (2*h)            # [b]\n",
        "        deriv_all.append(deriv_blk)\n",
        "\n",
        "    deriv = np.concatenate(deriv_all, axis=0)\n",
        "    Lfull_hat = float(np.max(deriv))\n",
        "    return Lfull_hat, deriv\n",
        "\n",
        "# --- Estimate ambient Lipschitz with a vector scorer (age+gender) and many dirs ---\n",
        "Lfull_hat, _ = estimate_Lfull_ambient_cdiff(w_ref, h=0.05, num_dirs=128, seed=7,\n",
        "                                            scorer_fn=clip_age_gender_vector)\n",
        "\n",
        "# Safety margins\n",
        "SAFETY_SUB   = 1.25   # already used for L_S\n",
        "SAFETY_FULL  = 1.50   # a bit stronger for ambient (harder problem)\n",
        "\n",
        "Ls_est_safe     = float(Ls_est_safe)        # from Block C\n",
        "Lfull_est_safe  = max(Ls_est_safe, Lfull_hat * SAFETY_FULL)  # fairness floor: ambient ≥ subspace\n",
        "\n",
        "# Print calibration constants so you can see fairness is enforced\n",
        "delta = 1e-5 if 'delta' not in globals() else delta\n",
        "import math\n",
        "C_sub = Ls_est_safe    * math.sqrt(2.0 * math.log(1.25/delta))\n",
        "C_iso = Lfull_est_safe * math.sqrt(2.0 * math.log(1.25/delta))\n",
        "print(f\"[Lipschitz] L_S_hat={Ls_hat:.4f}→safe={Ls_est_safe:.4f} ; \"\n",
        "      f\"L_full_hat={Lfull_hat:.4f}→safe={Lfull_est_safe:.4f}\")\n",
        "print(f\"[calibration] C_sub={C_sub:.4f}  C_iso={C_iso:.4f}  (δ={delta}, enforced C_iso ≥ C_sub → {C_iso >= C_sub})\")\n"
      ],
      "metadata": {
        "id": "ZLcEcwxvnZjT",
        "outputId": "815884b7-6503-4976-fa02-fe47e6460055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lipschitz] L_S_hat=0.2435→safe=0.3044 ; L_full_hat=0.2160→safe=0.3241\n",
            "[calibration] C_sub=1.4747  C_iso=1.5700  (δ=1e-05, enforced C_iso ≥ C_sub → True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === D: Monte‑Carlo experiment (subspace vs. isotropic norm-match vs. isotropic DP ambient) ===\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np, math, os\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "# Budgets\n",
        "eps_list = [0.2, 0.5, 1.0, 2.0]\n",
        "delta    = 1e-5\n",
        "tau_list = [0.5, 1.0]\n",
        "K        = 200  # set 50 for smoke tests, 200–300 for paper plots\n",
        "\n",
        "out_dir = '/content/results_empirical'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# (Optional) start fresh each run to avoid mixed-schema CSVs\n",
        "DELETE_OLD_CSV = True\n",
        "csv_path = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "if DELETE_OLD_CSV and os.path.exists(csv_path):\n",
        "    try:\n",
        "        os.remove(csv_path)\n",
        "        print(\"Removed old CSV; will write a fresh file.\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not remove old CSV:\", e)\n",
        "\n",
        "# Metrics\n",
        "def identity_ssim(img_ref, img):  return float(ssim(img_ref, img, channel_axis=2, data_range=255))\n",
        "def perceptual_1mssim(img_ref, img): return 1.0 - identity_ssim(img_ref, img)\n",
        "\n",
        "# Attack via CLIP (target ‘age’), label from reference (boundary-centered)\n",
        "y_ref = (clip_scores([x_ref])['age'][0] >= 0.0)\n",
        "def attack_success(img):\n",
        "    return 1 if (clip_scores([img])['age'][0] >= 0.0) == y_ref else 0\n",
        "\n",
        "# Leakage via CLIP (non-target ‘gender’)\n",
        "g_ref = clip_scores([x_ref])['gender'][0]\n",
        "def leakage(img):\n",
        "    return abs(clip_scores([img])['gender'][0] - g_ref)\n",
        "\n",
        "def clip_to_tau(vec, tau):\n",
        "    n = np.linalg.norm(vec)\n",
        "    return vec if n <= tau else vec * (tau / n)\n",
        "\n",
        "# Consistent 17-column CSV (method, eps, delta, tau, sigma, Ls_est, Lfull_est, attack_mean, attack_std, leak_mean, leak_std, id_mean, id_std, perc_mean, perc_std, alpha, margin)\n",
        "if not os.path.exists(csv_path):\n",
        "    with open(csv_path, 'w') as f:\n",
        "        f.write('method,eps,delta,tau,sigma,Ls_est,Lfull_est,attack_mean,attack_std,'\n",
        "                'leak_mean,leak_std,id_mean,id_std,perc_mean,perc_std,alpha,margin\\n')\n",
        "\n",
        "# Shapes\n",
        "d = Q.shape[0]; k = Q.shape[1]\n",
        "alpha_used = float(alpha_star)\n",
        "\n",
        "print(f\"[CALIBRATION] L_S_safe={Ls_est_safe:.4f}  L_full_safe={Lfull_est_safe:.4f}\")\n",
        "for tau in tau_list:\n",
        "    # precompute constants\n",
        "    base_const = math.sqrt(2.0 * math.log(1.25/delta))\n",
        "    for eps in eps_list:\n",
        "        # noise scales\n",
        "        sigma_sub    = (Ls_est_safe    * tau * base_const) / eps\n",
        "        sigma_iso_dp = (Lfull_est_safe * tau * base_const) / eps\n",
        "        tag_sub    = f'sub_eps{eps}_del{delta}_tau{tau}_sig{round(sigma_sub,4)}'\n",
        "        tag_iso_dp = f'isoDP_eps{eps}_del{delta}_tau{tau}_sig{round(sigma_iso_dp,4)}'\n",
        "        print(f\"[τ={tau}] [ε={eps}] σ_sub={sigma_sub:.4f}  σ_isoDP={sigma_iso_dp:.4f}\")\n",
        "\n",
        "        # stats containers\n",
        "        stats_sub, stats_iso_nm, stats_iso_dp = [], [], []\n",
        "\n",
        "        for ksample in range(K):\n",
        "            # --- Subspace mechanism: Δw = Q z_k, z_k ~ N(0, σ_sub^2 I_k), clip\n",
        "            z_k = np.random.normal(0.0, sigma_sub, size=(k,))\n",
        "            dw_sub = (Q @ z_k).astype(np.float64)\n",
        "            dw_sub = clip_to_tau(dw_sub, tau)\n",
        "\n",
        "            # --- Isotropic norm-matched (iso_nm): match ||dw_sub||, random ambient dir, then clip\n",
        "            u = np.random.normal(0.0, 1.0, size=(d,))\n",
        "            u /= (np.linalg.norm(u) + 1e-12)\n",
        "            dw_iso_nm = u * (np.linalg.norm(dw_sub) + 1e-12)\n",
        "            dw_iso_nm = clip_to_tau(dw_iso_nm, tau)\n",
        "\n",
        "            # --- Isotropic DP ambient (iso_dp): Δw ~ N(0, σ_iso_dp^2 I_d), then clip\n",
        "            z_d = np.random.normal(0.0, sigma_iso_dp, size=(d,))\n",
        "            dw_iso_dp = clip_to_tau(z_d.astype(np.float64), tau)\n",
        "\n",
        "            # Synthesize\n",
        "            x_sub    = generator.easy_synthesize((w_ref + dw_sub   )[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "            x_iso_nm = generator.easy_synthesize((w_ref + dw_iso_nm)[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "            x_iso_dp = generator.easy_synthesize((w_ref + dw_iso_dp)[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "\n",
        "            # Metrics\n",
        "            def mpack(x):\n",
        "                a = attack_success(x)\n",
        "                l = leakage(x)\n",
        "                i = identity_ssim(x_ref, x)\n",
        "                p = perceptual_1mssim(x_ref, x)\n",
        "                return (a, l, i, p)\n",
        "\n",
        "            stats_sub.append(mpack(x_sub))\n",
        "            stats_iso_nm.append(mpack(x_iso_nm))\n",
        "            stats_iso_dp.append(mpack(x_iso_dp))\n",
        "\n",
        "            # Save a few triplets (k<6) for F1\n",
        "            if ksample < 6:\n",
        "                base_sub    = f\"{out_dir}/age_{tag_sub}_k{ksample}\"\n",
        "                base_iso_dp = f\"{out_dir}/age_{tag_iso_dp}_k{ksample}\"\n",
        "                Image.fromarray(x_ref.astype(np.uint8)).save(base_sub + \"_ref.png\")\n",
        "                Image.fromarray(x_iso_dp.astype(np.uint8)).save(base_iso_dp + \"_iso_dp.png\")\n",
        "                Image.fromarray(x_sub.astype(np.uint8)).save(base_sub + \"_sub.png\")\n",
        "\n",
        "            if (ksample+1) % max(1, K//4) == 0:\n",
        "                print(f\"  progress {ksample+1}/{K}\")\n",
        "\n",
        "        def agg(arr):\n",
        "            A = np.array(arr, dtype=float)\n",
        "            return np.nanmean(A, axis=0), np.nanstd(A, axis=0)\n",
        "\n",
        "        # aggregate\n",
        "        m_sub,    s_sub    = agg(stats_sub)\n",
        "        m_iso_nm, s_iso_nm = agg(stats_iso_nm)\n",
        "        m_iso_dp, s_iso_dp = agg(stats_iso_dp)\n",
        "\n",
        "        # write rows (17 columns)\n",
        "        with open(csv_path, 'a') as f:\n",
        "            # iso_nm (norm-matched isotropic; record Lfull_est for reference)\n",
        "            f.write(f'iso_nm,{eps},{delta},{tau},{np.linalg.norm(dw_iso_nm):.6f},{Ls_est_safe},{Lfull_est_safe},'\n",
        "                    f'{m_iso_nm[0]},{s_iso_nm[0]},{m_iso_nm[1]},{s_iso_nm[1]},'\n",
        "                    f'{m_iso_nm[2]},{s_iso_nm[2]},{m_iso_nm[3]},{s_iso_nm[3]},{alpha_used},{SAFETY_SUB}\\n')\n",
        "            # iso_dp (DP ambient)\n",
        "            f.write(f'iso_dp,{eps},{delta},{tau},{sigma_iso_dp},{Ls_est_safe},{Lfull_est_safe},'\n",
        "                    f'{m_iso_dp[0]},{s_iso_dp[0]},{m_iso_dp[1]},{s_iso_dp[1]},'\n",
        "                    f'{m_iso_dp[2]},{s_iso_dp[2]},{m_iso_dp[3]},{s_iso_dp[3]},{alpha_used},{SAFETY_FULL}\\n')\n",
        "            # sub (your mechanism)\n",
        "            f.write(f'sub,{eps},{delta},{tau},{sigma_sub},{Ls_est_safe},{Lfull_est_safe},'\n",
        "                    f'{m_sub[0]},{s_sub[0]},{m_sub[1]},{s_sub[1]},'\n",
        "                    f'{m_sub[2]},{s_sub[2]},{m_sub[3]},{s_sub[3]},{alpha_used},{SAFETY_SUB}\\n')\n",
        "\n",
        "print(\"✅ calibrated run complete →\", out_dir)\n",
        "\n",
        "# Auto-download the CSV immediately\n",
        "try:\n",
        "    files.download(csv_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "uJhO5WmPXAMr",
        "outputId": "319085f8-bfce-43b0-8425-dd8d4106ad33"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed old CSV; will write a fresh file.\n",
            "[CALIBRATION] L_S_safe=0.3044  L_full_safe=0.3241\n",
            "[τ=0.5] [ε=0.2] σ_sub=3.6867  σ_isoDP=3.9250\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2450257577.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mstats_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mstats_iso_nm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_iso_nm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mstats_iso_dp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_iso_dp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# Save a few triplets (k<6) for F1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2450257577.py\u001b[0m in \u001b[0;36mmpack\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_success\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleakage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptual_1mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2450257577.py\u001b[0m in \u001b[0;36midentity_ssim\u001b[0;34m(img_ref, img)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0midentity_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperceptual_1mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0midentity_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0m_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_at_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructural_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mmssim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# compute (weighted) variances and covariances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0muxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0muyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36muniform_filter\u001b[0;34m(input, size, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m             uniform_filter1d(input, int(size), axis, output, mode,\n\u001b[0m\u001b[1;32m   1614\u001b[0m                              cval, origin)\n\u001b[1;32m   1615\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36muniform_filter1d\u001b[0;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcomplex_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m         _nd_image.uniform_filter1d(input, size, axis, output, mode, cval,\n\u001b[0m\u001b[1;32m   1540\u001b[0m                                    origin)\n\u001b[1;32m   1541\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make F2–F5 plots and a simple F1 grid (robust CSV loader that merges old/new schemas)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import math, glob, os, csv, numpy as np\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "raw_csv = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "norm_csv = f\"{out_dir}/summary_age_CLIPcalibrated_merged.csv\"\n",
        "\n",
        "# --- Normalize CSV: handle both 15-col (old) and 17-col (new) rows ---\n",
        "col17 = ['method','eps','delta','tau','sigma','Ls_est','Lfull_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha','margin']\n",
        "col15 = ['method','eps','delta','tau','sigma','Ls_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha']\n",
        "\n",
        "rows = []\n",
        "with open(raw_csv, newline='') as f:\n",
        "    rdr = csv.reader(f)\n",
        "    first = next(rdr, None)\n",
        "\n",
        "    # If the first row is a header, ignore it; otherwise treat it as data\n",
        "    def _ingest(r):\n",
        "        if not r:\n",
        "            return\n",
        "        if len(r) == 17:\n",
        "            rows.append(dict(zip(col17, r)))\n",
        "        elif len(r) == 15:\n",
        "            d = dict(zip(col15, r))\n",
        "            d['Lfull_est'] = ''\n",
        "            d['margin']    = ''\n",
        "            rows.append(d)\n",
        "        else:\n",
        "            # skip malformed rows\n",
        "            pass\n",
        "\n",
        "    if first and not (len(first) > 0 and first[0] == 'method'):\n",
        "        _ingest(first)\n",
        "    for r in rdr:\n",
        "        _ingest(r)\n",
        "\n",
        "# Build dataframe with unified schema\n",
        "df = pd.DataFrame(rows, columns=col17)\n",
        "\n",
        "# Cast numerics\n",
        "for c in col17:\n",
        "    if c != 'method':\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# Basic sanity: drop rows with missing eps/tau\n",
        "df = df.dropna(subset=['eps','tau'])\n",
        "df.to_csv(norm_csv, index=False)\n",
        "print(\"Normalized CSV written:\", norm_csv)\n",
        "\n",
        "# From now on, use the normalized dataframe `df`\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"Normalized CSV is empty. Re-run the Monte-Carlo cell (D) to generate results.\")\n",
        "\n",
        "# --- Plots ---\n",
        "def plot_metric(metric, ylabel, tau):\n",
        "    sub = df[(df['tau'] == tau)]\n",
        "    if sub.empty:\n",
        "        print(f\"No rows for tau={tau}\")\n",
        "        return None\n",
        "    plt.figure()\n",
        "    # legend order preference\n",
        "    order = [m for m in ['iso_dp','iso_nm','sub'] if m in sub['method'].unique()]\n",
        "    for method in order:\n",
        "        dsub = sub[sub['method'] == method].sort_values('eps')\n",
        "        if dsub.empty:\n",
        "            continue\n",
        "        y = dsub[metric].values\n",
        "        yerr = dsub[metric.replace('mean','std')].values\n",
        "        plt.errorbar(dsub['eps'], y, yerr=yerr, marker='o', label=method)\n",
        "    plt.xlabel('ε'); plt.ylabel(ylabel); plt.title(f'{ylabel} vs ε (τ={tau}, δ=1e-5)')\n",
        "    plt.legend(); plt.grid(True, alpha=0.2)\n",
        "    fn = f\"{out_dir}/{metric}_vs_eps_tau{tau}.png\"\n",
        "    plt.savefig(fn, bbox_inches='tight'); plt.close()\n",
        "    print(\"Saved\", fn)\n",
        "    return fn\n",
        "\n",
        "saved_figs = []\n",
        "for tau in sorted(df['tau'].dropna().unique()):\n",
        "    fn = plot_metric('attack_mean', 'Attack success (↓)', tau)       # F2\n",
        "    if fn: saved_figs.append(fn)\n",
        "    fn = plot_metric('leak_mean',   'Non-target leakage (↓)', tau)    # F3\n",
        "    if fn: saved_figs.append(fn)\n",
        "    fn = plot_metric('id_mean',     'Identity SSIM (↑)', tau)         # F4\n",
        "    if fn: saved_figs.append(fn)\n",
        "    # F5: Privacy vs Perceptual\n",
        "    subdf = df[df['tau']==tau]\n",
        "    if not subdf.empty:\n",
        "        plt.figure()\n",
        "        order = [m for m in ['iso_dp','iso_nm','sub'] if m in subdf['method'].unique()]\n",
        "        for method in order:\n",
        "            dmethod = subdf[subdf['method']==method]\n",
        "            if dmethod.empty:\n",
        "                continue\n",
        "            plt.scatter(1 - dmethod['attack_mean'], dmethod['perc_mean'], label=method)\n",
        "        plt.xlabel('Privacy = 1 - attack success (↑)')\n",
        "        plt.ylabel('Perceptual loss = 1 - SSIM (↓)')\n",
        "        plt.title(f'Privacy–Utility tradeoff (τ={tau}, δ=1e-5)'); plt.legend(); plt.grid(True, alpha=0.2)\n",
        "        fn = f\"{out_dir}/privacy_utility_tau{tau}.png\"\n",
        "        plt.savefig(fn, bbox_inches='tight'); plt.close(); print(\"Saved\", fn)\n",
        "        saved_figs.append(fn)\n",
        "\n",
        "# --- F1 grid (ref + iso_dp + sub), robust to float formatting ---\n",
        "def find_first_matching(path_glob):\n",
        "    g = glob.glob(path_glob)\n",
        "    return g[0] if len(g) > 0 else None\n",
        "\n",
        "rows = []\n",
        "for tau in sorted(df['tau'].unique()):\n",
        "    for eps in sorted(df['eps'].unique()):\n",
        "        sub_row    = df[(df['tau']==tau)&(df['eps']==eps)&(df['method']=='sub')]\n",
        "        isodp_row  = df[(df['tau']==tau)&(df['eps']==eps)&(df['method']=='iso_dp')]\n",
        "        if sub_row.empty or isodp_row.empty:\n",
        "            continue\n",
        "\n",
        "        # Use wildcards for sigma to avoid float-string mismatches\n",
        "        base_sub_glob    = f\"{out_dir}/age_sub_eps{eps}_del1e-05_tau{tau}_sig*_k0\"\n",
        "        base_iso_dp_glob = f\"{out_dir}/age_isoDP_eps{eps}_del1e-05_tau{tau}_sig*_k0\"\n",
        "        base_sub    = find_first_matching(base_sub_glob)\n",
        "        base_iso_dp = find_first_matching(base_iso_dp_glob)\n",
        "        if not base_sub or not base_iso_dp:\n",
        "            continue\n",
        "\n",
        "        p_ref = base_sub + \"_ref.png\"\n",
        "        p_iso = base_iso_dp + \"_iso_dp.png\"\n",
        "        p_sub = base_sub + \"_sub.png\"\n",
        "        if all(os.path.exists(p) for p in [p_ref, p_iso, p_sub]):\n",
        "            trip = [Image.open(p_ref), Image.open(p_iso), Image.open(p_sub)]\n",
        "            w = sum(im.width for im in trip); h = max(im.height for im in trip)\n",
        "            row = Image.new('RGB', (w,h))\n",
        "            x=0\n",
        "            for im in trip:\n",
        "                row.paste(im, (x,0)); x+=im.width\n",
        "            rows.append(row)\n",
        "\n",
        "if rows:\n",
        "    H = sum(r.height for r in rows); W = max(r.width for r in rows)\n",
        "    grid = Image.new('RGB', (W,H)); y=0\n",
        "    for r in rows:\n",
        "        grid.paste(r,(0,y)); y += r.height\n",
        "    grid_path = f\"{out_dir}/F1_qual_grid.png\"\n",
        "    grid.save(grid_path)\n",
        "    print(\"Saved\", grid_path)\n",
        "    saved_figs.append(grid_path)\n",
        "else:\n",
        "    print(\"F1 grid assembly skipped (no triplets found).\")\n",
        "\n",
        "# Auto-download key outputs individually (figures + grid)\n",
        "for p in saved_figs:\n",
        "    try: files.download(p)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n",
        "\n",
        "# Zip ALL results and download once (recommended)\n",
        "zip_path = '/content/results_empirical.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files_list in os.walk(out_dir):\n",
        "        for name in files_list:\n",
        "            full = os.path.join(root, name)\n",
        "            arc  = os.path.relpath(full, start=os.path.dirname(out_dir))\n",
        "            z.write(full, arcname=arc)\n",
        "print(\"Zipped:\", zip_path)\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "id": "eh10-Qp9XDKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Block F: Equal-utility matching with LPIPS (AlexNet) =====\n",
        "# Compares SUBSPACE (σ from L_S) vs ISOTROPIC tuned σ so that LPIPS matches SUB's LPIPS\n",
        "# Saves: results_empirical/summary_equalUtility.csv + F5_equal_utility_tau{tau}.png\n",
        "\n",
        "!pip -q install lpips\n",
        "import lpips, torch, numpy as np, math, os, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lpips_net = lpips.LPIPS(net='alex').to(device).eval()\n",
        "\n",
        "# -------- Helpers --------\n",
        "def _to_lpips_tensor(np_imgs):\n",
        "    \"\"\"\n",
        "    np_imgs: (B,H,W,3) uint8 or float in [0,255]\n",
        "    returns: torch float in [-1,1], shape (B,3,H,W)\n",
        "    \"\"\"\n",
        "    if np_imgs.ndim == 3:   # (H,W,3) -> (1,H,W,3)\n",
        "        np_imgs = np_imgs[None, ...]\n",
        "    arr = np_imgs.astype(np.float32) / 255.0\n",
        "    t = torch.from_numpy(arr).permute(0,3,1,2)  # B,3,H,W\n",
        "    t = t * 2.0 - 1.0\n",
        "    return t.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def lpips_mean(x_ref_np, x_batch_np):\n",
        "    \"\"\"Average LPIPS(x_batch, x_ref) over the batch.\"\"\"\n",
        "    Xr = _to_lpips_tensor(np.repeat(x_ref_np[None,...], x_batch_np.shape[0], axis=0))\n",
        "    X  = _to_lpips_tensor(x_batch_np)\n",
        "    d  = lpips_net(X, Xr)     # shape (B,1,1,1)\n",
        "    return float(d.mean().item())\n",
        "\n",
        "def clip_tau_batch(vecs, tau):\n",
        "    n = np.linalg.norm(vecs, axis=1, keepdims=True)\n",
        "    return vecs * np.minimum(1.0, tau/(n + 1e-12))\n",
        "\n",
        "def synth_from_latents(lat_batch):\n",
        "    # chunked synth to respect generator.batch_size\n",
        "    bs = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    imgs = []\n",
        "    for s in range(0, lat_batch.shape[0], bs):\n",
        "        chunk = lat_batch[s:s+bs]\n",
        "        im = generator.easy_synthesize(chunk, **synthesis_kwargs)['image']\n",
        "        imgs.append(im)\n",
        "    return np.concatenate(imgs, axis=0)  # (B,H,W,3)\n",
        "\n",
        "# Attack (same as before): target = sign(CLIP age at x_ref)\n",
        "y_ref = (clip_scores([x_ref])['age'][0] >= 0.0)\n",
        "def attack_success_batch(x_batch):\n",
        "    scores = clip_scores(x_batch)['age']   # shape [B]\n",
        "    preds  = (scores >= 0.0)\n",
        "    return float(np.mean((preds == y_ref).astype(np.float32)))\n",
        "\n",
        "# -------- Measurement routines --------\n",
        "def measure_subspace(K_eval, sigma_sub, tau):\n",
        "    \"\"\"Return (lpips_mean, attack_mean) for SUB at given sigma,tau using K_eval samples.\"\"\"\n",
        "    d, k = Q.shape\n",
        "    # Sample z ~ N(0, sigma^2 I_k), project, clip\n",
        "    z = np.random.normal(0.0, sigma_sub, size=(K_eval, k))\n",
        "    dw = (Q @ z.T).T\n",
        "    dw = clip_tau_batch(dw, tau)\n",
        "    lat = w_ref[None,:] + dw\n",
        "    imgs = synth_from_latents(lat)\n",
        "    lp  = lpips_mean(x_ref, imgs)\n",
        "    atk = attack_success_batch(imgs)\n",
        "    return lp, atk\n",
        "\n",
        "def measure_iso(K_eval, sigma_iso, tau):\n",
        "    \"\"\"Return (lpips_mean, attack_mean) for ISO at given sigma,tau using K_eval samples.\"\"\"\n",
        "    d = Q.shape[0]\n",
        "    z = np.random.normal(0.0, sigma_iso, size=(K_eval, d))  # Gaussian in R^d\n",
        "    z = clip_tau_batch(z, tau)\n",
        "    lat = w_ref[None,:] + z\n",
        "    imgs = synth_from_latents(lat)\n",
        "    lp  = lpips_mean(x_ref, imgs)\n",
        "    atk = attack_success_batch(imgs)\n",
        "    return lp, atk\n",
        "\n",
        "def tune_sigma_iso_to_match_lpips(tau, lp_target, sigma_init, K_lp=64, iters=7, tol=2e-3):\n",
        "    \"\"\"\n",
        "    Binary-search sigma_iso so ISO LPIPS ≈ lp_target.\n",
        "    Start bracket around sigma_init; widen if needed.\n",
        "    \"\"\"\n",
        "    # Initial bracket around DP-calibrated iso sigma\n",
        "    lo, hi = sigma_init * 0.25, sigma_init * 4.0\n",
        "\n",
        "    # Ensure bracket covers target (expand adaptively if needed)\n",
        "    lp_lo, _ = measure_iso(max(32, K_lp//2), lo, tau)\n",
        "    lp_hi, _ = measure_iso(max(32, K_lp//2), hi, tau)\n",
        "    expand = 0\n",
        "    while not (lp_lo <= lp_target <= lp_hi) and expand < 3:\n",
        "        lo *= 0.5; hi *= 2.0\n",
        "        lp_lo, _ = measure_iso(max(32, K_lp//2), lo, tau)\n",
        "        lp_hi, _ = measure_iso(max(32, K_lp//2), hi, tau)\n",
        "        expand += 1\n",
        "\n",
        "    sigma = sigma_init\n",
        "    for _ in range(iters):\n",
        "        mid = 0.5 * (lo + hi)\n",
        "        lp_mid, _ = measure_iso(K_lp, mid, tau)\n",
        "        if lp_mid < lp_target - tol:\n",
        "            lo = mid\n",
        "        elif lp_mid > lp_target + tol:\n",
        "            hi = mid\n",
        "        else:\n",
        "            sigma = mid\n",
        "            break\n",
        "        sigma = mid\n",
        "    return sigma\n",
        "\n",
        "# -------- Main loop: equal-utility pairs --------\n",
        "sqrt_term = math.sqrt(2.0 * math.log(1.25 / 1e-5))  # δ fixed at 1e-5 here\n",
        "C_sub = Ls_est_safe * sqrt_term\n",
        "# Lfull_est_safe should have been computed earlier for iso_dp; if not, set C_iso=None\n",
        "C_iso = (Lfull_est_safe * sqrt_term) if ('Lfull_est_safe' in globals()) else None\n",
        "\n",
        "eq_csv = f\"{out_dir}/summary_equalUtility.csv\"\n",
        "if not os.path.exists(eq_csv):\n",
        "    with open(eq_csv, 'w') as f:\n",
        "        f.write('tau,eps_sub,sigma_sub,lpips_sub,attack_sub,'\n",
        "                'sigma_iso_match,lpips_iso_match,attack_iso_match,'\n",
        "                'eps_iso_implied\\n')\n",
        "\n",
        "K_lp   = 64    # samples to measure LPIPS in tuning\n",
        "K_eval = 128   # samples to measure final attack at the matched LPIPS\n",
        "\n",
        "for tau in tau_list:\n",
        "    rows_print = []\n",
        "    for eps in eps_list:\n",
        "        # Subspace σ from DP-style calibration\n",
        "        sigma_sub = (C_sub * tau) / eps\n",
        "\n",
        "        # Measure SUB LPIPS and attack\n",
        "        lp_sub, atk_sub = measure_subspace(K_lp, sigma_sub, tau)\n",
        "\n",
        "        # ISO_DP σ (if available); else use sigma_sub as a starting scale\n",
        "        sigma_iso_dp = ( (C_iso * tau) / eps ) if C_iso is not None else sigma_sub\n",
        "\n",
        "        # Tune ISO σ to match SUB LPIPS\n",
        "        sigma_iso_match = tune_sigma_iso_to_match_lpips(tau, lp_sub, sigma_iso_dp, K_lp=K_lp)\n",
        "        lp_iso, atk_iso = measure_iso(K_eval, sigma_iso_match, tau)\n",
        "\n",
        "        # Implied epsilon for the matched ISO point (if we know C_iso)\n",
        "        eps_iso_implied = (C_iso * tau / sigma_iso_match) if C_iso is not None else float('nan')\n",
        "\n",
        "        with open(eq_csv, 'a') as f:\n",
        "            f.write(f'{tau},{eps},{sigma_sub},{lp_sub},{atk_sub},'\n",
        "                    f'{sigma_iso_match},{lp_iso},{atk_iso},{eps_iso_implied}\\n')\n",
        "\n",
        "        rows_print.append((eps, lp_sub, atk_sub, lp_iso, atk_iso, sigma_iso_match, eps_iso_implied))\n",
        "\n",
        "    # Pretty print per-τ summary\n",
        "    print(f\"\\n[Equal-utility @ τ={tau}]  (LPIPS matched to SUB)\")\n",
        "    print(\"eps_sub |  LPIPS  SUB  | Attack SUB |  LPIPS  ISO  | Attack ISO |  σ_iso_match  |  eps_iso_implied\")\n",
        "    for (eps, lp_s, a_s, lp_i, a_i, s_iso, e_iso) in rows_print:\n",
        "        e_iso_str = f\"{e_iso:.3f}\" if not math.isnan(e_iso) else \"nan\"\n",
        "        print(f\"{eps:6.2f} |  {lp_s:10.4f} |   {a_s:9.3f} |  {lp_i:10.4f} |   {a_i:9.3f} |  {s_iso:12.4f} |  {e_iso_str}\")\n",
        "\n",
        "# Auto-download CSV (Colab)\n",
        "try:\n",
        "    files.download(eq_csv)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped:\", e)\n",
        "\n",
        "# -------- Plot: Attack at matched LPIPS (per τ) --------\n",
        "eq = pd.read_csv(eq_csv)\n",
        "for tau in sorted(eq['tau'].unique()):\n",
        "    sub = eq[eq['tau']==tau].sort_values('eps_sub')\n",
        "    plt.figure()\n",
        "    plt.plot(sub['eps_sub'], sub['attack_sub'], marker='o', label='sub (LPIPS target)')\n",
        "    plt.plot(sub['eps_sub'], sub['attack_iso_match'], marker='s', label='iso (LPIPS matched)')\n",
        "    plt.xlabel('ε (of SUB point)'); plt.ylabel('Attack success (↓)')\n",
        "    plt.title(f'Attack @ matched LPIPS (τ={tau})')\n",
        "    plt.grid(True, alpha=0.2); plt.legend()\n",
        "    fig_path = f\"{out_dir}/F5_equal_utility_tau{tau}.png\"\n",
        "    plt.savefig(fig_path, bbox_inches='tight'); plt.close()\n",
        "    print(\"Saved\", fig_path)\n",
        "    try: files.download(fig_path)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "id": "ha1Z7-OKCvGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === OPTIONAL: Verification (calibration, mechanism, win-rates, latent leakage) ===\n",
        "import math, numpy as np, pandas as pd, csv, os\n",
        "\n",
        "csv_path = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "\n",
        "# --- Normalize CSV: accept both 15-col (old) and 17-col (new) formats ---\n",
        "col17 = ['method','eps','delta','tau','sigma','Ls_est','Lfull_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha','margin']\n",
        "col15 = ['method','eps','delta','tau','sigma','Ls_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha']\n",
        "\n",
        "def load_normalized(csv_path):\n",
        "    rows = []\n",
        "    with open(csv_path, newline='') as f:\n",
        "        rdr = csv.reader(f)\n",
        "        first = next(rdr, None)\n",
        "\n",
        "        def ingest(r):\n",
        "            if not r:\n",
        "                return\n",
        "            # skip header line if present\n",
        "            if r[0] == 'method':\n",
        "                return\n",
        "            if len(r) == 17:\n",
        "                rows.append(dict(zip(col17, r)))\n",
        "            elif len(r) == 15:\n",
        "                d = dict(zip(col15, r))\n",
        "                d['Lfull_est'] = ''\n",
        "                d['margin']    = ''\n",
        "                rows.append(d)\n",
        "            else:\n",
        "                # malformed row length → skip\n",
        "                return\n",
        "\n",
        "        # If the first line is data (not header), ingest it\n",
        "        if first and first[0] != 'method':\n",
        "            ingest(first)\n",
        "        for r in rdr:\n",
        "            ingest(r)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=col17)\n",
        "    # cast numerics (leave 'method' as string)\n",
        "    for c in col17:\n",
        "        if c != 'method':\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "    # drop rows with missing eps/tau\n",
        "    df = df.dropna(subset=['eps','tau'])\n",
        "    return df\n",
        "\n",
        "dfv = load_normalized(csv_path)\n",
        "print(\"Rows:\", len(dfv))\n",
        "print(\"Methods present:\", sorted(dfv['method'].dropna().unique()))\n",
        "\n",
        "# --- Calibration constants (robust) ---\n",
        "def _get_global(name, default=np.nan):\n",
        "    return globals()[name] if name in globals() else default\n",
        "\n",
        "delta_val = _get_global('delta', 1e-5)\n",
        "Ls_safe   = _get_global('Ls_est_safe', np.nan)     # subspace L_S (with safety)\n",
        "Lf_safe   = _get_global('Lfull_est_safe', np.nan)  # ambient L (with safety), optional\n",
        "\n",
        "# Fallback from CSV if not defined in this session\n",
        "if (not np.isfinite(Ls_safe)) and 'Ls_est' in dfv.columns and dfv['Ls_est'].notna().any():\n",
        "    # prefer 'sub' rows for Ls_est\n",
        "    tmp = dfv[dfv['method']=='sub']['Ls_est'].dropna()\n",
        "    if tmp.shape[0] == 0:\n",
        "        tmp = dfv['Ls_est'].dropna()\n",
        "    if tmp.shape[0] > 0:\n",
        "        Ls_safe = float(tmp.iloc[0])\n",
        "\n",
        "if (not np.isfinite(Lf_safe)) and 'Lfull_est' in dfv.columns and dfv['Lfull_est'].notna().any():\n",
        "    # prefer iso_dp rows for Lfull_est, else any available\n",
        "    tmp = dfv[dfv['method']=='iso_dp']['Lfull_est'].dropna()\n",
        "    if tmp.shape[0] == 0:\n",
        "        tmp = dfv['Lfull_est'].dropna()\n",
        "    if tmp.shape[0] > 0:\n",
        "        Lf_safe = float(tmp.iloc[0])\n",
        "\n",
        "def _calib_const(Lsafe):\n",
        "    return (Lsafe * math.sqrt(2.0 * math.log(1.25/delta_val))) if np.isfinite(Lsafe) else float('nan')\n",
        "\n",
        "C_sub = _calib_const(Ls_safe)\n",
        "C_iso = _calib_const(Lf_safe)\n",
        "print(f\"[calibration] C_sub={C_sub:.4f}  C_iso={C_iso:.4f}  (δ={delta_val})\")\n",
        "\n",
        "# --- Mechanism audit (subspace projection + clipping) ---\n",
        "b = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "tau = 0.5; eps = 0.5\n",
        "sigma_sub = (Ls_safe * tau * math.sqrt(2.0 * math.log(1.25/delta_val))) / eps\n",
        "d, k = Q.shape\n",
        "\n",
        "z = np.random.normal(0.0, sigma_sub, size=(b, k))\n",
        "dw_sub = (Q @ z.T).T\n",
        "# projection residual\n",
        "proj = (Q @ (Q.T @ dw_sub.T)).T\n",
        "residual = np.linalg.norm(dw_sub - proj, axis=1) / (np.linalg.norm(dw_sub, axis=1) + 1e-12)\n",
        "\n",
        "def clip_tau_batch(vecs, tau):\n",
        "    n = np.linalg.norm(vecs, axis=1, keepdims=True)\n",
        "    return vecs * np.minimum(1.0, tau/(n+1e-12))\n",
        "\n",
        "dw_sub_c = clip_tau_batch(dw_sub, tau)\n",
        "norms = np.linalg.norm(dw_sub_c, axis=1)\n",
        "print(f\"[audit] subspace residual (median, max): {np.median(residual):.2e}, {np.max(residual):.2e}\")\n",
        "print(f\"[audit] clip ||Δw_sub|| ≤ τ ? max norm = {norms.max():.4f}  (τ={tau})\")\n",
        "\n",
        "# --- Win-rate summary: sub vs best available isotropic baseline ---\n",
        "def choose_baseline(methods):\n",
        "    if 'iso_dp' in methods: return 'iso_dp'\n",
        "    if 'iso'    in methods: return 'iso'\n",
        "    if 'iso_nm' in methods: return 'iso_nm'\n",
        "    return None\n",
        "\n",
        "baseline = choose_baseline(set(dfv['method'].dropna().unique()))\n",
        "if baseline is None:\n",
        "    print(\"No isotropic baseline found (iso_dp / iso / iso_nm); skipping win-rate summary.\")\n",
        "else:\n",
        "    def win_rate(df, metric, better='lower', m1='sub', m2=baseline):\n",
        "        pivot = df.pivot_table(index=['tau','eps'], columns='method', values=f'{metric}_mean')\n",
        "        # keep only rows where both methods exist\n",
        "        cols = [c for c in [m1, m2] if c in pivot.columns]\n",
        "        if len(cols) < 2:\n",
        "            return 0, 0\n",
        "        pivot = pivot.dropna(subset=cols, how='any')\n",
        "        if pivot.empty:\n",
        "            return 0, 0\n",
        "        if better == 'lower':\n",
        "            wins = (pivot[m1] < pivot[m2]).sum()\n",
        "        else:\n",
        "            wins = (pivot[m1] > pivot[m2]).sum()\n",
        "        return int(wins), int(pivot.shape[0])\n",
        "\n",
        "    for metr, better in [('attack','lower'), ('leak','lower'), ('id','higher')]:\n",
        "        w, t = win_rate(dfv, metr, better, 'sub', baseline)\n",
        "        print(f\"{metr} ({'↓' if better=='lower' else '↑'})  sub better than {baseline} in {w}/{t} budgets\")\n",
        "\n",
        "    # Perceptual gap (keep utility similar)\n",
        "    pivot_pq = dfv.pivot_table(index=['tau','eps'], columns='method', values='perc_mean')\n",
        "    if ('sub' in pivot_pq.columns) and (baseline in pivot_pq.columns):\n",
        "        rel_gap = (pivot_pq['sub'] - pivot_pq[baseline]).abs().mean()\n",
        "        print(f\"mean |Δ(perceptual)| between sub and {baseline}: {float(rel_gap):.4f}\")\n",
        "    else:\n",
        "        print(\"Perceptual comparison skipped (columns missing).\")\n",
        "\n",
        "# --- Latent leakage sanity (gender direction) ---\n",
        "Kcheck = 200\n",
        "z = np.random.normal(0.0, sigma_sub, size=(Kcheck, k))\n",
        "dw_sub = (Q @ z.T).T\n",
        "dw_sub = clip_tau_batch(dw_sub, tau)\n",
        "\n",
        "u = np.random.normal(0.0, 1.0, size=(Kcheck, d))\n",
        "u /= (np.linalg.norm(u, axis=1, keepdims=True) + 1e-12)\n",
        "dw_nm = u * (np.linalg.norm(dw_sub, axis=1, keepdims=True) + 1e-12)\n",
        "dw_nm = clip_tau_batch(dw_nm, tau)\n",
        "\n",
        "print(\"latent leakage |Δw·b_gender|  mean(sub), mean(iso_nm):\",\n",
        "      float(np.mean(np.abs(dw_sub @ b_gender))),\n",
        "      float(np.mean(np.abs(dw_nm  @ b_gender))))\n"
      ],
      "metadata": {
        "id": "a7LmiwFO-7VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Compact F1 grids for IEEE (one-column width) ===\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os, math, numpy as np, pandas as pd\n",
        "\n",
        "df = pd.read_csv(f\"{out_dir}/summary_age_CLIPcalibrated.csv\")\n",
        "\n",
        "# Where the triplets are saved (from your Monte-Carlo block naming)\n",
        "def triplet_paths(tau, eps, sigma_sub, sigma_iso_dp):\n",
        "    base_sub    = f\"{out_dir}/age_sub_eps{eps}_del1e-05_tau{tau}_sig{round(sigma_sub,4)}_k0\"\n",
        "    base_iso_dp = f\"{out_dir}/age_isoDP_eps{eps}_del1e-05_tau{tau}_sig{round(sigma_iso_dp,4)}_k0\"\n",
        "    return {\n",
        "        'ref': base_sub + \"_ref.png\",\n",
        "        'iso': base_iso_dp + \"_iso_dp.png\",\n",
        "        'sub': base_sub + \"_sub.png\"\n",
        "    }\n",
        "\n",
        "def safe_open(path):\n",
        "    return Image.open(path).convert(\"RGB\") if os.path.exists(path) else None\n",
        "\n",
        "def draw_label(img, text, bar_h=18):\n",
        "    w,h = img.size\n",
        "    bar = Image.new('RGB', (w, bar_h), (255,255,255))\n",
        "    im2 = Image.new('RGB', (w, h+bar_h), (255,255,255))\n",
        "    im2.paste(img, (0,0)); im2.paste(bar, (0,h))\n",
        "    d = ImageDraw.Draw(im2)\n",
        "    d.text((6, h+2), text, fill=(0,0,0))\n",
        "    return im2\n",
        "\n",
        "def build_f1_for_tau(tau, eps_show=(0.2,0.5,1.0,2.0),\n",
        "                     cell=128, pad=6, column_width_px=1050, font_note=True):\n",
        "    # gather per-ε sigmas\n",
        "    row_sub = df[(df['tau']==tau)&(df['method']=='sub')].set_index('eps')\n",
        "    row_iso = df[(df['tau']==tau)&(df['method']=='iso_dp')].set_index('eps')\n",
        "    cols = []\n",
        "    for eps in eps_show:\n",
        "        if eps not in row_sub.index or eps not in row_iso.index:\n",
        "            continue\n",
        "        sig_sub = row_sub.loc[eps, 'sigma']\n",
        "        sig_iso = row_iso.loc[eps, 'sigma']\n",
        "        paths = triplet_paths(tau, eps, sig_sub, sig_iso)\n",
        "        ref = safe_open(paths['ref']); iso = safe_open(paths['iso']); sub = safe_open(paths['sub'])\n",
        "        if not (ref and iso and sub):\n",
        "            continue\n",
        "        # thumbnail to cell size (square)\n",
        "        ref = ref.resize((cell,cell), Image.BICUBIC)\n",
        "        iso = iso.resize((cell,cell), Image.BICUBIC)\n",
        "        sub = sub.resize((cell,cell), Image.BICUBIC)\n",
        "        # label with (ε,σ_sub)\n",
        "        lab = f\"ε={eps:g}, σ_sub={sig_sub:.2f}\"\n",
        "        ref = draw_label(ref, lab)\n",
        "        iso = draw_label(iso, \"Iso-DP\")\n",
        "        sub = draw_label(sub, \"Subspace\")\n",
        "        # stack 3 rows (Ref, Iso, Sub) into one column\n",
        "        col_h = ref.size[1] + iso.size[1] + sub.size[1] + 2*pad\n",
        "        col   = Image.new('RGB', (cell, col_h), (255,255,255))\n",
        "        y=0\n",
        "        for im in [ref, iso, sub]:\n",
        "            col.paste(im, (0,y)); y += im.size[1] + pad\n",
        "        cols.append(col)\n",
        "\n",
        "    if not cols:\n",
        "        print(f\"[F1] No triplets found for τ={tau}\")\n",
        "        return None\n",
        "\n",
        "    # concat columns with padding\n",
        "    w_each = cols[0].size[0]\n",
        "    h_max  = max(c.size[1] for c in cols)\n",
        "    W = len(cols)*w_each + (len(cols)-1)*pad\n",
        "    H = h_max\n",
        "    grid = Image.new('RGB', (W,H), (255,255,255))\n",
        "    x=0\n",
        "    for c in cols:\n",
        "        # vertical center each column\n",
        "        y0 = (H - c.size[1])//2\n",
        "        grid.paste(c, (x,y0))\n",
        "        x += w_each + pad\n",
        "\n",
        "    # scale to IEEE 1-column width\n",
        "    if W > column_width_px:\n",
        "        new_h = int(H * (column_width_px / W))\n",
        "        grid = grid.resize((column_width_px, new_h), Image.BICUBIC)\n",
        "\n",
        "    outp = f\"{out_dir}/F1_qual_grid_tau{tau}_ieee.png\"\n",
        "    grid.save(outp, optimize=True, quality=95)\n",
        "    print(\"Saved\", outp)\n",
        "    return outp\n",
        "\n",
        "# build for both τ=0.5 and τ=1.0\n",
        "g1 = build_f1_for_tau(0.5)\n",
        "g2 = build_f1_for_tau(1.0)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    for p in [g1,g2]:\n",
        "        if p: files.download(p)\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "print(\"For LaTeX (IEEEtran):\")\n",
        "print(r\"\"\"\\begin{figure}[t]\n",
        "  \\centering\n",
        "  \\includegraphics[width=\\columnwidth]{results_empirical/F1_qual_grid_tau0.5_ieee}\n",
        "  \\caption{Qualitative comparison at $\\tau{=}0.5$. Columns: $\\epsilon\\in\\{0.2,0.5,1.0,2.0\\}$ (labeled with $\\sigma_{\\text{sub}}$). Rows: reference, Iso-DP, Subspace.}\n",
        "\\end{figure}\"\"\")\n"
      ],
      "metadata": {
        "id": "6d3VOcGyMaoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}