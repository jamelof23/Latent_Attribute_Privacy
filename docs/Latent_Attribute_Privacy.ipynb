{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Latent_Attribute_Privacy.ipynb",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Codebase and Models"
      ],
      "metadata": {
        "id": "iXIucaWWpoVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'Latent_Attribute_Privacy'\n",
        "!git clone https://github.com/jamelof23/Latent_Attribute_Privacy $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}/models/interfacegan_official')\n",
        "!wget https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O /content/Latent_Attribute_Privacy/models/interfacegan_official/models/pretrain/stylegan_ffhq.pth --quiet"
      ],
      "metadata": {
        "id": "tyMo0VCfprkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Utility Functions"
      ],
      "metadata": {
        "id": "XpgN0pa0pwg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL.Image\n",
        "\n",
        "import torch\n",
        "\n",
        "# A dictionary containing information about the models available (e.g., pggan, stylegan).\n",
        "from models.model_settings import MODEL_POOL\n",
        "\n",
        "from models.stylegan_generator import StyleGANGenerator\n",
        "\n",
        "\n",
        "def build_generator(model_name):\n",
        "  \"\"\"Builds the generator by model name.\"\"\"\n",
        "  gan_type = MODEL_POOL[model_name]['gan_type']\n",
        "  if gan_type == 'stylegan':\n",
        "    generator = StyleGANGenerator(model_name)\n",
        "  return generator\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import IPython.display as display\n",
        "import io\n",
        "\n",
        "def imshow(image, viz_size=256):\n",
        "\n",
        "    # Ensure the input is a single image\n",
        "    if image.ndim != 3:\n",
        "        raise ValueError(\"Input must be a single image with 3 dimensions (height, width, channels).\")\n",
        "\n",
        "    # Resize the image if necessary\n",
        "    height, width, channels = image.shape\n",
        "    if height != viz_size or width != viz_size:\n",
        "        image = cv2.resize(image, (viz_size, viz_size))\n",
        "\n",
        "    # Convert image to a displayable format\n",
        "    image = np.asarray(image, dtype=np.uint8)\n",
        "    data = io.BytesIO()\n",
        "    Image.fromarray(image).save(data, 'jpeg')\n",
        "    im_data = data.getvalue()\n",
        "\n",
        "    # Display the image\n",
        "    return display.display(display.Image(im_data))"
      ],
      "metadata": {
        "id": "-s7RBNULp0Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select a Model"
      ],
      "metadata": {
        "id": "SE18UQjbqHuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "model_name = \"stylegan_ffhq\"  # Always use 'stylegan_ffhq'\n",
        "latent_space_type = \"W\"       # Always use latent space type 'W'\n",
        "\n",
        "# Function to build and load the generator model\n",
        "generator = build_generator(model_name)\n",
        "\n",
        "# List of attributes for manipulation\n",
        "ATTRS = ['age', 'gender']\n",
        "# Dictionary to store attribute boundaries\n",
        "boundaries = {}\n",
        "\n",
        "# Loading Attribute Boundaries\n",
        "for attr_name in ATTRS:\n",
        "    boundary_name = f'{model_name}_{attr_name}'\n",
        "    # Load the correct boundary file based on the latent space type\n",
        "    boundary_path = f'boundaries/{boundary_name}_w_boundary.npy'\n",
        "    boundaries[attr_name] = np.load(boundary_path)\n"
      ],
      "metadata": {
        "id": "8jeFZnt3qBqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload initial latent code for a synthesized image"
      ],
      "metadata": {
        "id": "eVYhSVzVqS5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "#num_samples = 1\n",
        "\n",
        "# Upload the .npy file\n",
        "print(\"[INFO] Please upload your latent vector (.npy file):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded latent vector\n",
        "npy_file_name = list(uploaded.keys())[0]\n",
        "latent_codes = np.load(npy_file_name)\n",
        "\n",
        "# Ensure that the latent vector is in the correct format (numpy.ndarray) and shape\n",
        "if not isinstance(latent_codes, np.ndarray) or latent_codes.shape != (1, 512):\n",
        "    raise ValueError(f\"Latent codes must be a numpy.ndarray with shape (1, 512), but got {latent_codes.shape}\")\n",
        "\n",
        "# Use W space for StyleGAN synthesis\n",
        "synthesis_kwargs = {'latent_space_type': 'W'}\n",
        "\n",
        "# Generate the image using customized latent vector\n",
        "images = generator.easy_synthesize(latent_codes, **synthesis_kwargs)['image']\n",
        "\n",
        "# Extract the first image (assuming images has a batch dimension)\n",
        "if images.ndim == 4:  # e.g., (batch_size, height, width, channels)\n",
        "    images = images[0]\n",
        "\n",
        "# Ensure the image is in the correct shape\n",
        "if images.ndim != 3:\n",
        "    raise ValueError(f\"Generated image must have shape (height, width, channels), but got {images.shape}\")\n",
        "\n",
        "# Display the generated image\n",
        "imshow(images)"
      ],
      "metadata": {
        "id": "L1t9sQI7qXFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Privatizing attributes for synthesized image"
      ],
      "metadata": {
        "id": "MUcaEVERWBFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Differential Privacy Parameters\n",
        "epsilon = 0.5  # @param {\"type\":\"slider\",\"min\":0.01,\"max\":1,\"step\":0.01}\n",
        "delta = 0.00001  # @param {type:\"slider\", min:1e-7, max:1e-3, step:1e-7}\n",
        "clipping_threshold = 1  # @param {type:\"slider\", min:0, max:10, step:0.05}\n",
        "\n",
        "\n",
        "# Dropdown Menu for Attribute Selection\n",
        "attribute_selection = \"Age\"  # @param [\"Age\", \"Gender\"]\n",
        "\n",
        "# Function to orthogonalize boundaries\n",
        "def orthogonalize_boundaries(boundaries):\n",
        "\n",
        "    \"\"\"\n",
        "    Orthogonalizes the attribute boundaries using Gram-Schmidt process.\n",
        "\n",
        "    Args:\n",
        "        boundaries (dict): Dictionary of attribute boundaries.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of orthogonalized attribute boundaries.\n",
        "    \"\"\"\n",
        "\n",
        "    orthogonal_boundaries = {}\n",
        "    keys = list(boundaries.keys())\n",
        "    for i, key_i in enumerate(keys):\n",
        "        boundary_i = boundaries[key_i].copy()\n",
        "        for j in range(i):\n",
        "            key_j = keys[j]\n",
        "            boundary_j = orthogonal_boundaries[key_j]\n",
        "            projection = np.dot(boundary_i.flatten(), boundary_j.flatten()) / np.dot(boundary_j.flatten(), boundary_j.flatten())\n",
        "            boundary_i -= projection * boundary_j\n",
        "        orthogonal_boundaries[key_i] = boundary_i / np.linalg.norm(boundary_i)  # Normalize\n",
        "    return orthogonal_boundaries\n",
        "\n",
        "# Orthogonalize the boundaries\n",
        "orthogonal_boundaries = orthogonalize_boundaries(boundaries)\n",
        "\n",
        "\n",
        "# Assuming snsitivity\n",
        "lambda_i = 1\n",
        "\n",
        "# Function to add scalar noise\n",
        "def add_scalar_noise(epsilon, delta, sensitivity):\n",
        "    sigma = (sensitivity * np.sqrt(2 * np.log(1.25 / delta))) / epsilon\n",
        "    return np.random.normal(0, sigma)\n",
        "\n",
        "\n",
        "\n",
        "# Copy the original latent codes\n",
        "new_codes = latent_codes.copy()\n",
        "\n",
        "# Map attribute_selection to the list of attributes to modify\n",
        "if attribute_selection == \"Age\":\n",
        "    selected_attributes = [\"age\"]\n",
        "elif attribute_selection == \"Gender\":\n",
        "    selected_attributes = [\"gender\"]\n",
        "else:\n",
        "    selected_attributes = []\n",
        "\n",
        "\n",
        "# Initialize the total update vector\n",
        "delta_w_total = np.zeros_like(new_codes)\n",
        "\n",
        "# Accumulate semantic shifts with noise\n",
        "for attr_name in selected_attributes:\n",
        "    # Retrieve the orthogonalized boundary for the attribute\n",
        "    boundary = orthogonal_boundaries[attr_name]\n",
        "\n",
        "    # Generate scalar noise for the attribute\n",
        "    scalar_noise = add_scalar_noise(epsilon, delta, lambda_i)\n",
        "\n",
        "    # Compute the semantic shift\n",
        "    delta_w_total += scalar_noise * boundary\n",
        "\n",
        "# Clip the total update to norm <= clipping_threshold\n",
        "norm = np.linalg.norm(delta_w_total)\n",
        "if norm > clipping_threshold:\n",
        "    delta_w_total = (clipping_threshold / norm) * delta_w_total\n",
        "\n",
        "# Apply the clipped update to the latent codes\n",
        "new_codes += delta_w_total\n",
        "\n",
        "# Generate the new images\n",
        "new_images = generator.easy_synthesize(new_codes, **synthesis_kwargs)['image']\n",
        "\n",
        "# Ensure only a single image is passed to imshow\n",
        "if new_images.ndim == 4:  # If batch dimension exists\n",
        "    new_images = new_images[0]\n",
        "\n",
        "# Validate the image shape\n",
        "if new_images.ndim != 3:\n",
        "    raise ValueError(f\"Generated image must have shape (height, width, channels), but got {new_images.shape}\")\n",
        "\n",
        "# Display the new image\n",
        "imshow(new_images)\n"
      ],
      "metadata": {
        "id": "paQD9jVNWBnR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
