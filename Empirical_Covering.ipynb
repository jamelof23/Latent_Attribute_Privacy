{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamelof23/Latent_Attribute_Privacy/blob/main/Empirical_Covering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup + load InterfaceGAN generator (GPU) + boundaries + latent\n",
        "# ==== ENV & REPO ====\n",
        "import os, sys, io, cv2, numpy as np\n",
        "from PIL import Image\n",
        "import IPython.display as display\n",
        "\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'Latent_Attribute_Privacy'\n",
        "!git clone -q https://github.com/jamelof23/Latent_Attribute_Privacy $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}/models/interfacegan_official')\n",
        "!mkdir -p models/pretrain\n",
        "!wget -q https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O models/pretrain/stylegan_ffhq.pth\n",
        "\n",
        "# ==== IMPORTS ====\n",
        "from models.model_settings import MODEL_POOL\n",
        "from models.stylegan_generator import StyleGANGenerator\n",
        "from google.colab import files  # for auto-downloads\n",
        "\n",
        "def build_generator(model_name):\n",
        "    gan_type = MODEL_POOL[model_name]['gan_type']\n",
        "    assert gan_type == 'stylegan'\n",
        "    return StyleGANGenerator(model_name)\n",
        "\n",
        "model_name = \"stylegan_ffhq\"\n",
        "latent_space_type = \"W\"  # we work in W\n",
        "generator = build_generator(model_name)\n",
        "synthesis_kwargs = {'latent_space_type': 'W'}\n",
        "print(\"✅ Generator ready.\")\n",
        "\n",
        "# ==== BOUNDARIES: Age (target), Gender (non-target) ====\n",
        "# Put your .npy boundaries under: Latent_Attribute_Privacy/models/interfacegan_official/boundaries/\n",
        "# e.g. stylegan_ffhq_age_w_boundary.npy, stylegan_ffhq_gender_w_boundary.npy\n",
        "age_path    = 'boundaries/stylegan_ffhq_age_w_boundary.npy'\n",
        "gender_path = 'boundaries/stylegan_ffhq_gender_w_boundary.npy'\n",
        "assert os.path.exists(age_path) and os.path.exists(gender_path), \"Boundary npy files not found.\"\n",
        "\n",
        "b_age    = np.load(age_path).astype(np.float64).reshape(-1)\n",
        "b_gender = np.load(gender_path).astype(np.float64).reshape(-1)\n",
        "\n",
        "# Normalize\n",
        "b_age    /= (np.linalg.norm(b_age) + 1e-12)\n",
        "b_gender /= (np.linalg.norm(b_gender) + 1e-12)\n",
        "\n",
        "# ==== UPLOAD LATENT ====\n",
        "print(\"[INFO] Upload latent .npy (shape (1,512) or (512,))\")\n",
        "uploaded = files.upload()\n",
        "latent_path = list(uploaded.keys())[0]\n",
        "latent_codes = np.load(latent_path).astype(np.float64)\n",
        "if latent_codes.ndim == 2 and latent_codes.shape == (1,512):\n",
        "    w0 = latent_codes[0]\n",
        "elif latent_codes.ndim == 1 and latent_codes.shape[0] == 512:\n",
        "    w0 = latent_codes\n",
        "else:\n",
        "    raise ValueError(f\"Latent must be (1,512) or (512,), got {latent_codes.shape}\")\n",
        "\n",
        "# Quick preview synth\n",
        "def imshow(image, viz=256):\n",
        "    h, w, _ = image.shape\n",
        "    if (h,w)!=(viz,viz):\n",
        "        image = cv2.resize(image, (viz, viz))\n",
        "    buf = io.BytesIO(); Image.fromarray(image.astype(np.uint8)).save(buf,'jpeg')\n",
        "    display.display(display.Image(buf.getvalue()))\n",
        "\n",
        "x0 = generator.easy_synthesize(w0[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "print(\"Original latent image:\")\n",
        "imshow(x0)\n",
        "\n",
        "# Save & auto-download the original image\n",
        "orig_path = '/content/original.png'\n",
        "Image.fromarray(x0.astype(np.uint8)).save(orig_path)\n",
        "try:\n",
        "    files.download(orig_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped (Colab-only):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "bfBoSnicW0r6",
        "outputId": "74183a8e-0ccd-46b3-98d7-6733270d9cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generator ready.\n",
            "[INFO] Upload latent .npy (shape (1,512) or (512,))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a75b222-5de7-4c74-a2fb-51b6d5c7dd49\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a75b222-5de7-4c74-a2fb-51b6d5c7dd49\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 777.npy to 777.npy\n",
            "Original latent image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_388576ce-4e22-4bf6-ae02-cbbcb8e268d0\", \"original.png\", 1154322)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SUBSPACE S from boundaries (Age target; can add more cols for joint case) ====\n",
        "# For single-attribute Age: N = [b_age]; for joint add more columns, e.g., np.stack([b_age, b_smile, ...], 1)\n",
        "\n",
        "# (A) Orthogonalize Age against Gender to reduce leakage\n",
        "def cosine(u, v):\n",
        "    return float(np.dot(u, v) / ((np.linalg.norm(u)+1e-12)*(np.linalg.norm(v)+1e-12)))\n",
        "\n",
        "print(f\"[diag] cos(angle(age, gender)) BEFORE = {cosine(b_age, b_gender):.4f}\")\n",
        "b_age_orth = b_age - (np.dot(b_age, b_gender)) * b_gender\n",
        "b_age_orth /= (np.linalg.norm(b_age_orth) + 1e-12)\n",
        "print(f\"[diag] cos(angle(age_orth, gender)) AFTER  = {cosine(b_age_orth, b_gender):.4e}\")\n",
        "\n",
        "# Use the orthogonalized Age for the subspace\n",
        "N = b_age_orth[:,None]  # d x k ; here k=1\n",
        "\n",
        "# Orthonormalize N -> Q_S (Gram–Schmidt via QR)\n",
        "Q, _ = np.linalg.qr(N)  # d x k, columns orthonormal\n",
        "k = Q.shape[1]\n",
        "d = Q.shape[0]\n",
        "print(f\"Subspace dim k={k}, ambient d={d}\")\n",
        "\n",
        "# Projector Pi_S = Q Q^T (we'll use Q directly for sampling)\n",
        "# Pi_S = Q @ Q.T  # not needed explicitly for sampling\n",
        "\n",
        "# ==== Reference edit (temporary) ====\n",
        "alpha_init = 2.0  # initial guess (not final)\n",
        "w_tmp = w0 + alpha_init * b_age_orth\n",
        "x_tmp = generator.easy_synthesize(w_tmp[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "Image.fromarray(x_tmp.astype(np.uint8)).save('/content/ref_alpha_init.png')\n",
        "\n",
        "# ==== CLIP scorer f_S  (public attribute scorer) ====\n",
        "!pip -q install open_clip_torch ftfy regex\n",
        "import torch, open_clip\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "clip_model, clip_preprocess, _ = open_clip.create_model_and_transforms(\n",
        "    'ViT-B-16', pretrained='laion2b_s34b_b88k', device=device)\n",
        "clip_model = clip_model.to(device)\n",
        "clip_model.eval()\n",
        "clip_tokenizer = open_clip.get_tokenizer('ViT-B-16')\n",
        "\n",
        "# Prompts (face-specific helps stability)\n",
        "texts_age    = clip_tokenizer([\"a young adult face, portrait\", \"an elderly face, portrait\"]).to(device)\n",
        "texts_gender = clip_tokenizer([\"a portrait photo of a male face\", \"a portrait photo of a female face\"]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    text_emb_age    = clip_model.encode_text(texts_age);    text_emb_age    /= text_emb_age.norm(dim=-1, keepdim=True)\n",
        "    text_emb_gender = clip_model.encode_text(texts_gender); text_emb_gender /= text_emb_gender.norm(dim=-1, keepdim=True)\n",
        "\n",
        "def _prep_batch(np_batch):\n",
        "    ims = [Image.fromarray(img.astype(np.uint8)) for img in np_batch]\n",
        "    ims = torch.stack([clip_preprocess(im) for im in ims]).to(device)\n",
        "    return ims\n",
        "\n",
        "@torch.no_grad()\n",
        "def clip_scores(np_batch):\n",
        "    \"\"\"\n",
        "    Returns dict with COSINE scores (no logit_scale) for age (old-young) and gender (woman-man).\n",
        "    Each entry shape: [batch]\n",
        "    \"\"\"\n",
        "    ims = _prep_batch(np_batch)\n",
        "    img_emb = clip_model.encode_image(ims); img_emb /= img_emb.norm(dim=-1, keepdim=True)\n",
        "    logits_age    = (img_emb @ text_emb_age.T)      # [B,2] cosine\n",
        "    logits_gender = (img_emb @ text_emb_gender.T)   # [B,2] cosine\n",
        "    age_score    = (logits_age[:,1] - logits_age[:,0]).detach().cpu().numpy()       # old - young\n",
        "    gender_score = (logits_gender[:,1] - logits_gender[:,0]).detach().cpu().numpy() # woman - man\n",
        "    return {'age': age_score, 'gender': gender_score}\n",
        "\n",
        "# Re-center w_ref near CLIP age boundary (score ≈ 0)\n",
        "def line_search_alpha_to_score0(w0, v, a_min=-5.0, a_max=5.0, steps=201):\n",
        "    alphas = np.linspace(a_min, a_max, steps)\n",
        "    lat_batch = w0[None,:] + alphas[:,None] * v[None,:]\n",
        "    bs = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    imgs_list = []\n",
        "    for s in range(0, steps, bs):\n",
        "        imgs_list.append(generator.easy_synthesize(lat_batch[s:s+bs], **synthesis_kwargs)['image'])\n",
        "    imgs = np.concatenate(imgs_list, axis=0)\n",
        "    scores = clip_scores(imgs)['age']  # >0 older, <0 younger\n",
        "    idx = int(np.argmin(np.abs(scores)))\n",
        "    return float(alphas[idx]), float(scores[idx]), alphas, scores\n",
        "\n",
        "def find_bracket_for_zero(alphas, scores):\n",
        "    # Find consecutive indices with sign change\n",
        "    for i in range(len(alphas)-1):\n",
        "        if np.sign(scores[i]) == 0:\n",
        "            return alphas[i], alphas[i]\n",
        "        if np.sign(scores[i]) != np.sign(scores[i+1]):\n",
        "            return alphas[i], alphas[i+1]\n",
        "    return None\n",
        "\n",
        "def refine_alpha_bisection(w0, v, a_lo, a_hi, scorer_fn, iters=14):\n",
        "    alo, ahi = float(a_lo), float(a_hi)\n",
        "    # if degenerate bracket (exact zero), return\n",
        "    if alo == ahi:\n",
        "        x_mid = generator.easy_synthesize((w0 + alo*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "        s_mid = scorer_fn([x_mid])['age'][0]\n",
        "        return alo, s_mid\n",
        "    # ensure opposite signs\n",
        "    x_lo = generator.easy_synthesize((w0 + alo*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "    x_hi = generator.easy_synthesize((w0 + ahi*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "    s_lo = scorer_fn([x_lo])['age'][0]\n",
        "    s_hi = scorer_fn([x_hi])['age'][0]\n",
        "    if np.sign(s_lo) == np.sign(s_hi):\n",
        "        # fallback: return the closer-to-zero endpoint\n",
        "        if abs(s_lo) <= abs(s_hi): return alo, s_lo\n",
        "        else: return ahi, s_hi\n",
        "    for _ in range(iters):\n",
        "        amid = 0.5*(alo+ahi)\n",
        "        x_mid = generator.easy_synthesize((w0 + amid*v)[None,:], **synthesis_kwargs)['image'][0]\n",
        "        s_mid = scorer_fn([x_mid])['age'][0]\n",
        "        if s_mid == 0: return amid, s_mid\n",
        "        if np.sign(s_mid) == np.sign(s_lo):\n",
        "            alo, s_lo = amid, s_mid\n",
        "        else:\n",
        "            ahi, s_hi = amid, s_mid\n",
        "    return amid, s_mid\n",
        "\n",
        "alpha_star0, score0, alphas_scan, scores_scan = line_search_alpha_to_score0(w0, b_age_orth, -5.0, 5.0, 201)\n",
        "br = find_bracket_for_zero(alphas_scan, scores_scan)\n",
        "if br is not None:\n",
        "    alpha_star, score_at_alpha = refine_alpha_bisection(w0, b_age_orth, br[0], br[1], clip_scores, iters=14)\n",
        "else:\n",
        "    alpha_star, score_at_alpha = alpha_star0, score0\n",
        "\n",
        "print(f\"[anchor refined] α ≈ {alpha_star:.4f}  score ≈ {score_at_alpha:.4e}\")\n",
        "\n",
        "w_ref = (w0 + alpha_star * b_age_orth).astype(np.float64)\n",
        "x_ref = generator.easy_synthesize(w_ref[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "Image.fromarray(x_ref.astype(np.uint8)).save('/content/ref_recentered.png')\n",
        "print(\"Reference (re-centered) image:\")\n",
        "imshow(x_ref)\n",
        "\n",
        "# Auto-download reference images\n",
        "for p in ['/content/ref_alpha_init.png', '/content/ref_recentered.png']:\n",
        "    try: files.download(p)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741,
          "referenced_widgets": [
            "99426144dbe648a29aa21e29c90ef190",
            "147a3cdad079466a83890425f5f1137d",
            "f521c60fc86c4d91a273ec59ba52168c",
            "d49b0833fc9647b987a49617bfe610e6",
            "81f437e6e2114b6395a0f21fcfb1bbe3",
            "fbb33a1867cb40c198a6384e451a0eda",
            "865a18cc307041318a1313f0eb2565c0",
            "9a59f45b70b346c2b97d331325cb0fbe",
            "11025bd118d840979a309d9119d8164a",
            "f7e5c9e49ca54dd0bc75e10433f9f1ea",
            "19056f5cfcbb43beb4c27ce72dd15abc"
          ]
        },
        "id": "vbnXi7qRW8lV",
        "outputId": "53916491-a0e0-43e0-c620-e80969bc979c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[diag] cos(angle(age, gender)) BEFORE = 0.0706\n",
            "[diag] cos(angle(age_orth, gender)) AFTER  = 1.4156e-13\n",
            "Subspace dim k=1, ambient d=512\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99426144dbe648a29aa21e29c90ef190"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[anchor refined] α ≈ 4.8000  score ≈ -7.4372e-03\n",
            "Reference (re-centered) image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f5ffaf5-92e1-4e15-bcea-174cf8e30d38\", \"ref_alpha_init.png\", 1239898)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1be7b563-f6bc-4d13-90a1-d20ba4bb4e56\", \"ref_recentered.png\", 1398197)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# C‑LC: Local‑Cover estimate of L_S for each tau (robust)\n",
        "# ==============================\n",
        "import numpy as np, math\n",
        "\n",
        "# --------- Required globals (asserts make failures obvious) ---------\n",
        "assert 'w_ref' in globals(), \"w_ref (latent, shape (d,)) is missing\"\n",
        "assert 'Q'     in globals(), \"Q (d×k subspace basis) is missing\"\n",
        "assert 'generator' in globals(), \"generator with .easy_synthesize is missing\"\n",
        "assert 'clip_scores' in globals(), \"clip_scores(np_batch)->dict is missing\"\n",
        "if 'synthesis_kwargs' not in globals():\n",
        "    synthesis_kwargs = {}  # safe default\n",
        "\n",
        "# --------- Tunables (override any of these above this cell if you like) ---------\n",
        "if 'tau_list' not in globals() or len(tau_list) == 0:\n",
        "    tau_list = [0.5, 1.0]                      # radii to certify\n",
        "\n",
        "gamma_margin = float(globals().get('gamma_margin', 2.0))  # margin multiplier for cover\n",
        "K_dirs       = int(globals().get('K_dirs', 12))           # # of directions (k>1)\n",
        "radii_fracs  = tuple(globals().get('radii_fracs', (0.0, 0.5, 1.0)))  # radii in [0, tau]\n",
        "h_dir        = float(globals().get('h_dir', 0.05))        # central diff step along subspace dirs\n",
        "num_v_dirs   = int(globals().get('num_v_dirs', 16))       # random test dirs for s(w)\n",
        "seed_cover   = int(globals().get('seed_cover', 0))\n",
        "seed_dirs    = int(globals().get('seed_dirs', 0))\n",
        "DUP_TOL      = float(globals().get('DUP_TOL', 1e-9))      # tolerance for near-duplicate points\n",
        "\n",
        "# Optional: list of attributes for scorer stacking, e.g. ['age','gender'].\n",
        "# If not provided, we'll auto-pick (age+gender if available, else age).\n",
        "SCORER_ATTRS = globals().get('SCORER_ATTRS', None)\n",
        "\n",
        "# --------- Helpers ---------\n",
        "def _synthesize_batch(lat_batch):\n",
        "    \"\"\"Chunked synth to respect generator.batch_size; returns np.array (B,H,W,3).\"\"\"\n",
        "    bs = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    out = []\n",
        "    for s in range(0, lat_batch.shape[0], bs):\n",
        "        out.append(generator.easy_synthesize(lat_batch[s:s+bs], **synthesis_kwargs)['image'])\n",
        "    return np.concatenate(out, axis=0)\n",
        "\n",
        "def _scorer_local_cover(np_batch):\n",
        "    \"\"\"\n",
        "    Uses SCORER_ATTRS if provided, else tries (age,gender) if available, else 'age', else first key.\n",
        "    Returns [B] or [B,m].\n",
        "    \"\"\"\n",
        "    s = clip_scores(np_batch)\n",
        "    if isinstance(s, dict):\n",
        "        if SCORER_ATTRS:\n",
        "            arrs = [s[a] for a in SCORER_ATTRS]\n",
        "            return np.stack(arrs, axis=1)\n",
        "        keys = set(s.keys())\n",
        "        if {'age','gender'}.issubset(keys):\n",
        "            return np.stack([s['age'], s['gender']], axis=1)\n",
        "        if 'age' in keys:\n",
        "            return s['age']\n",
        "        k0 = next(iter(keys))\n",
        "        return s[k0]\n",
        "    return s\n",
        "\n",
        "def _estimate_s_at_w(w, Q, scorer_fn, h_dir=0.05, num_v_dirs=16, seed=0):\n",
        "    \"\"\"\n",
        "    s(w) = ||J_f(w) Q||_2  via directional central differences:\n",
        "       ≈ max_v  || f(w+h·Qv) - f(w-h·Qv) || / (2h),   v ~ Unif(S^{k-1})\n",
        "    scorer_fn returns [B] or [B,m].\n",
        "    \"\"\"\n",
        "    d, k = Q.shape\n",
        "    rng = np.random.default_rng(seed)\n",
        "    V = rng.normal(size=(num_v_dirs, k))\n",
        "    V /= (np.linalg.norm(V, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "    lat_plus, lat_minus = [], []\n",
        "    for v in V:\n",
        "        dv = Q @ v\n",
        "        lat_plus.append (w + h_dir * dv)\n",
        "        lat_minus.append(w - h_dir * dv)\n",
        "    lat_pair = np.vstack([np.stack(lat_plus), np.stack(lat_minus)])  # [2*num_v, d]\n",
        "\n",
        "    imgs = _synthesize_batch(lat_pair)\n",
        "    s = np.asarray(scorer_fn(imgs))\n",
        "    if s.ndim == 1:\n",
        "        s_plus, s_minus = s[:len(V)], s[len(V):]\n",
        "        deriv = np.abs(s_plus - s_minus) / (2*h_dir)                 # [num_v]\n",
        "    elif s.ndim == 2:\n",
        "        s_plus, s_minus = s[:len(V), :], s[len(V):, :]\n",
        "        deriv = np.linalg.norm(s_plus - s_minus, axis=1) / (2*h_dir) # [num_v]\n",
        "    else:\n",
        "        raise ValueError(f\"scorer_fn must return [B] or [B,m], got shape {s.shape}\")\n",
        "    return float(deriv.max())\n",
        "\n",
        "# --- PATCHED: robust cover builder (handles k=1; avoid duplicates at t=0) ---\n",
        "def _build_cover_points(w_ref, Q, tau, K_dirs=12, radii_fracs=(0.0, 0.5, 1.0), seed=0):\n",
        "    \"\"\"\n",
        "    Cover points: { w_ref + t_j * u_i } with u_i unit in S and t_j in [0, tau].\n",
        "    - For k=1, use directions U = {+1, -1} (exact, no duplicates).\n",
        "    - For t=0, add exactly ONE center point (avoid K duplicates at the origin).\n",
        "    \"\"\"\n",
        "    k = Q.shape[1]\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    if k == 1:\n",
        "        U = np.array([[1.0], [-1.0]], dtype=float)  # deterministic, no dupes\n",
        "    else:\n",
        "        U = rng.normal(size=(K_dirs, k))\n",
        "        U /= (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)  # unit in R^k\n",
        "\n",
        "    radii = tau * np.array(radii_fracs, dtype=float)\n",
        "    cover = []\n",
        "    for t in radii:\n",
        "        if np.isclose(t, 0.0):\n",
        "            cover.append(w_ref.copy())                    # only ONE center point\n",
        "        else:\n",
        "            for u in U:\n",
        "                cover.append(w_ref + (Q @ (t * u)))\n",
        "    cover = np.stack(cover, axis=0)\n",
        "    return cover, U, radii  # [N, d], [K,k], [T]\n",
        "\n",
        "# --- PATCHED: robust covering radius (ignore duplicates/near-duplicates) ---\n",
        "def _cover_radius(pts, tol=DUP_TOL):\n",
        "    \"\"\"\n",
        "    Approx covering radius in ambient space:\n",
        "      max_i min_{j!=i} ||p_i - p_j||,\n",
        "    but ignore duplicate/near-duplicate points (< tol) so they don't force radius ~ 0.\n",
        "    \"\"\"\n",
        "    N = pts.shape[0]\n",
        "    if N <= 1:\n",
        "        return 0.0\n",
        "    dists = np.linalg.norm(pts[:,None,:] - pts[None,:,:], axis=-1)\n",
        "    np.fill_diagonal(dists, np.inf)   # ignore self\n",
        "    dists[dists < tol] = np.inf       # ignore (near-)duplicates\n",
        "    min_d = np.min(dists, axis=1)\n",
        "    min_d = np.where(np.isfinite(min_d), min_d, 0.0)  # rows with no distinct neighbor → 0\n",
        "    return float(np.max(min_d))\n",
        "\n",
        "# --- PATCHED: robust MhatJ estimate (ignore duplicate neighbors) ---\n",
        "def _estimate_MJ(pts, s_vals, tol=DUP_TOL):\n",
        "    \"\"\"\n",
        "    Rough Lipschitz constant of s(w)=||J_f(w)Q|| on the cover:\n",
        "      max_i |s_i - s_j(i)| / ||w_i - w_j(i)||,\n",
        "    where j(i) is the nearest DISTINCT neighbor (distance >= tol).\n",
        "    \"\"\"\n",
        "    N = pts.shape[0]\n",
        "    if N <= 1:\n",
        "        return 0.0\n",
        "    dists = np.linalg.norm(pts[:,None,:] - pts[None,:,:], axis=-1)\n",
        "    np.fill_diagonal(dists, np.inf)\n",
        "    dists[dists < tol] = np.inf  # ignore (near-)duplicates\n",
        "    nn_idx  = np.argmin(dists, axis=1)\n",
        "    nn_dist = dists[np.arange(N), nn_idx]\n",
        "    mask = np.isfinite(nn_dist) & (nn_dist > 0)\n",
        "    ratios = np.zeros(N, dtype=float)\n",
        "    if np.any(mask):\n",
        "        ratios[mask] = np.abs(s_vals[mask] - s_vals[nn_idx[mask]]) / nn_dist[mask]\n",
        "    return float(np.max(ratios))\n",
        "\n",
        "def estimate_LS_local_cover(\n",
        "    w_ref, Q, tau,\n",
        "    scorer_fn,\n",
        "    K_dirs=12, radii_fracs=(0.0, 0.5, 1.0),\n",
        "    h_dir=0.05, num_v_dirs=16,\n",
        "    gamma_margin=2.0,\n",
        "    seed_cover=0, seed_dirs=0\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns (Lhat_cover_safe, details) where:\n",
        "      Lhat_cover_safe = max_w s(w) + gamma_margin * MhatJ * h_cover\n",
        "      with s(w) ≈ max_v directional central diff at w inside subspace S.\n",
        "    \"\"\"\n",
        "    cover_pts, U, radii = _build_cover_points(w_ref, Q, tau, K_dirs, radii_fracs, seed_cover)\n",
        "\n",
        "    # Evaluate s(w) at each cover point\n",
        "    s_vals = []\n",
        "    for i, w in enumerate(cover_pts):\n",
        "        s_vals.append(_estimate_s_at_w(w, Q, scorer_fn, h_dir=h_dir, num_v_dirs=num_v_dirs, seed=seed_dirs+i))\n",
        "    s_vals = np.array(s_vals, dtype=float)\n",
        "    s_max = float(np.max(s_vals)) if s_vals.size else 0.0\n",
        "\n",
        "    # Mesh/cover parameters for the safety margin\n",
        "    h_cover = _cover_radius(cover_pts)           # robust covering radius\n",
        "    MhatJ   = _estimate_MJ(cover_pts, s_vals)    # robust local smoothness of s(w)\n",
        "    beta    = gamma_margin * MhatJ * h_cover\n",
        "    Lhat_cover_safe = s_max + beta\n",
        "\n",
        "    details = {\n",
        "        's_max': s_max,\n",
        "        'h_cover': h_cover,\n",
        "        'MhatJ': MhatJ,\n",
        "        'beta': beta,\n",
        "        'cover_count': cover_pts.shape[0],\n",
        "        'K_dirs': K_dirs,\n",
        "        'radii': list(map(float, radii)),\n",
        "        'num_v_dirs': num_v_dirs,\n",
        "        'h_dir': h_dir,\n",
        "        'gamma_margin': gamma_margin\n",
        "    }\n",
        "    return Lhat_cover_safe, details\n",
        "\n",
        "# --------- Compute LS_COVER for all tau (used by Block D) ---------\n",
        "LS_COVER   = {}\n",
        "LS_DETAILS = {}\n",
        "for tau in tau_list:\n",
        "    Lhat, info = estimate_LS_local_cover(\n",
        "        w_ref, Q, tau,\n",
        "        scorer_fn=_scorer_local_cover,\n",
        "        K_dirs=K_dirs, radii_fracs=radii_fracs,\n",
        "        h_dir=h_dir, num_v_dirs=num_v_dirs,\n",
        "        gamma_margin=gamma_margin,\n",
        "        seed_cover=seed_cover, seed_dirs=seed_dirs\n",
        "    )\n",
        "    LS_COVER[tau]   = float(Lhat)\n",
        "    LS_DETAILS[tau] = info\n",
        "\n",
        "print(\"[C‑LC] Completed. Per‑τ safe L_S estimates:\")\n",
        "for t in tau_list:\n",
        "    inf = LS_DETAILS[t]\n",
        "    print(f\"  τ={t}: Lhat_safe={LS_COVER[t]:.6f}  (s_max={inf['s_max']:.6f}, β={inf['beta']:.6f}, \"\n",
        "          f\"h_cover={inf['h_cover']:.6e}, MhatJ={inf['MhatJ']:.3e}, cover={inf['cover_count']})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5AUpVOnW9cm",
        "outputId": "27ad1daf-aae4-4c45-e3a1-31708a29b2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[C‑LC] Completed. Per‑τ safe L_S estimates:\n",
            "  τ=0.5: Lhat_safe=0.478545  (s_max=0.235970, β=0.242575, h_cover=2.500000e-01, MhatJ=4.851e-01, cover=5)\n",
            "  τ=1.0: Lhat_safe=0.493573  (s_max=0.268414, β=0.225159, h_cover=5.000000e-01, MhatJ=2.252e-01, cover=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === D: Monte‑Carlo experiment (subspace vs. isotropic norm‑match vs. isotropic DP ambient)\n",
        "import os, math, csv, glob, numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# -----------------------------\n",
        "# Budgets / defaults\n",
        "# -----------------------------\n",
        "if 'eps_list' not in globals(): eps_list = [0.2, 0.5, 1.0, 2.0]\n",
        "if 'tau_list' not in globals(): tau_list = [0.5, 1.0]\n",
        "delta = globals().get('delta', 1e-5)\n",
        "K     = int(globals().get('K_MC', 200))  # 50 for smoke tests, 200–300 for paper plots\n",
        "\n",
        "out_dir = '/content/results_empirical'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def identity_ssim(img_ref, img):   # higher is better\n",
        "    return float(ssim(img_ref, img, channel_axis=2, data_range=255))\n",
        "\n",
        "def perceptual_1mssim(img_ref, img):   # lower is better\n",
        "    return 1.0 - identity_ssim(img_ref, img)\n",
        "\n",
        "# Attack via CLIP (target = sign at x_ref)\n",
        "y_ref = (clip_scores([x_ref])['age'][0] >= 0.0)\n",
        "def attack_success(img):\n",
        "    return 1 if (clip_scores([img])['age'][0] >= 0.0) == y_ref else 0\n",
        "\n",
        "# Leakage via CLIP (non-target gender)\n",
        "g_ref = clip_scores([x_ref])['gender'][0]\n",
        "def leakage(img):\n",
        "    return abs(clip_scores([img])['gender'][0] - g_ref)\n",
        "\n",
        "def clip_to_tau(vec, tau):\n",
        "    n = np.linalg.norm(vec)\n",
        "    return vec if n <= tau else vec * (tau / (n + 1e-12))\n",
        "\n",
        "# -----------------------------\n",
        "# Ambient Lipschitz fallback (if not provided)\n",
        "# -----------------------------\n",
        "def clip_age_gender_vector(np_batch):\n",
        "    s = clip_scores(np_batch)\n",
        "    return np.stack([s['age'], s['gender']], axis=1)\n",
        "\n",
        "def estimate_Lfull_ambient_cdiff(\n",
        "    w_ref, h=0.05, num_dirs=128, seed=7, scorer_fn=clip_age_gender_vector\n",
        "):\n",
        "    \"\"\"Ambient spectral norm via central differences over random directions in R^d.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    d = w_ref.shape[0]\n",
        "    dirs = rng.normal(size=(num_dirs, d))\n",
        "    dirs /= (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "    bs_default = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    deriv_all = []\n",
        "    for s0 in range(0, num_dirs, bs_default):\n",
        "        v = dirs[s0:s0+bs_default]\n",
        "        lat_plus  = w_ref[None,:] + h * v\n",
        "        lat_minus = w_ref[None,:] - h * v\n",
        "        imgs_p = generator.easy_synthesize(lat_plus,  **synthesis_kwargs)['image']\n",
        "        imgs_m = generator.easy_synthesize(lat_minus, **synthesis_kwargs)['image']\n",
        "        s_p = np.asarray(scorer_fn(imgs_p))\n",
        "        s_m = np.asarray(scorer_fn(imgs_m))\n",
        "        if s_p.ndim == 1:\n",
        "            deriv_blk = np.abs(s_p - s_m) / (2*h)\n",
        "        else:\n",
        "            deriv_blk = np.linalg.norm(s_p - s_m, axis=-1) / (2*h)\n",
        "        deriv_all.append(deriv_blk)\n",
        "    deriv = np.concatenate(deriv_all, axis=0)\n",
        "    return float(np.max(deriv)), deriv\n",
        "\n",
        "# Prepare per‑tau Local‑Cover constants (must come from C‑LC)\n",
        "if 'LS_COVER' not in globals() or not isinstance(LS_COVER, dict) or len(LS_COVER)==0:\n",
        "    raise RuntimeError(\"LS_COVER not found. Run Block C‑LC first (it now computes LS_COVER).\")\n",
        "\n",
        "sqrt_term = math.sqrt(2.0 * math.log(1.25 / delta))\n",
        "C_SUB_BY_TAU = {tau: LS_COVER[tau] * sqrt_term for tau in LS_COVER}\n",
        "\n",
        "# Ambient constant (estimate if missing)\n",
        "if 'Lfull_est_safe' not in globals():\n",
        "    Lfull_hat, _ = estimate_Lfull_ambient_cdiff(w_ref, h=0.05, num_dirs=128, seed=7)\n",
        "    SAFETY_FULL  = float(globals().get('SAFETY_FULL', 1.50))  # slightly stronger safety for ambient\n",
        "    Lfull_est_safe = max(Lfull_hat * SAFETY_FULL, max(LS_COVER.values()))\n",
        "    print(f\"[Ambient] L_full_hat={Lfull_hat:.4f}  → safe={Lfull_est_safe:.4f}\")\n",
        "else:\n",
        "    print(f\"[Ambient] using provided safe L_full={Lfull_est_safe:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# CSV init (17 columns)\n",
        "# -----------------------------\n",
        "csv_path = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "if os.path.exists(csv_path):\n",
        "    try:\n",
        "        os.remove(csv_path)\n",
        "    except Exception as e:\n",
        "        print(\"Could not remove old CSV:\", e)\n",
        "\n",
        "with open(csv_path, 'w') as f:\n",
        "    f.write('method,eps,delta,tau,sigma,Ls_est,Lfull_est,'\n",
        "            'attack_mean,attack_std,leak_mean,leak_std,'\n",
        "            'id_mean,id_std,perc_mean,perc_std,alpha,margin\\n')\n",
        "\n",
        "# -----------------------------\n",
        "# Monte‑Carlo loops\n",
        "# -----------------------------\n",
        "d = Q.shape[0]; k = Q.shape[1]\n",
        "alpha_used = float(globals().get('alpha_star', 0.0))\n",
        "gamma_margin_val = float(globals().get('gamma_margin', 2.0))  # from Local‑Cover block\n",
        "\n",
        "print(f\"[CALIBRATION] per‑tau C_sub and ambient C_iso ready  (δ={delta})\")\n",
        "for tau in tau_list:\n",
        "    base_const_sub = C_SUB_BY_TAU[tau]\n",
        "    base_const_iso = Lfull_est_safe * sqrt_term\n",
        "    for eps in eps_list:\n",
        "        sigma_sub    = (base_const_sub * tau) / eps\n",
        "        sigma_iso_dp = (base_const_iso * tau) / eps\n",
        "        tag_sub    = f'sub_eps{eps}_del{delta}_tau{tau}_sig{round(sigma_sub,4)}'\n",
        "        tag_iso_dp = f'isoDP_eps{eps}_del{delta}_tau{tau}_sig{round(sigma_iso_dp,4)}'\n",
        "        print(f\"[τ={tau}] [ε={eps}] σ_sub={sigma_sub:.4f}  σ_isoDP={sigma_iso_dp:.4f}\")\n",
        "\n",
        "        stats_sub, stats_iso_nm, stats_iso_dp = [], [], []\n",
        "\n",
        "        for ksample in range(K):\n",
        "            # --- Subspace mechanism: Δw = Q z_k, z_k ~ N(0, σ_sub^2 I_k), then clip\n",
        "            z_k = np.random.normal(0.0, sigma_sub, size=(k,))\n",
        "            dw_sub = (Q @ z_k).astype(np.float64)\n",
        "            dw_sub = clip_to_tau(dw_sub, tau)\n",
        "\n",
        "            # --- Isotropic norm-matched: match ||Δw_sub|| in a random ambient direction, then clip\n",
        "            u = np.random.normal(0.0, 1.0, size=(d,))\n",
        "            u /= (np.linalg.norm(u) + 1e-12)\n",
        "            dw_iso_nm = u * (np.linalg.norm(dw_sub) + 1e-12)\n",
        "            dw_iso_nm = clip_to_tau(dw_iso_nm, tau)\n",
        "\n",
        "            # --- Isotropic DP ambient: Δw ~ N(0, σ_iso_dp^2 I_d), then clip\n",
        "            z_d = np.random.normal(0.0, sigma_iso_dp, size=(d,))\n",
        "            dw_iso_dp = clip_to_tau(z_d.astype(np.float64), tau)\n",
        "\n",
        "            # Synthesize\n",
        "            x_sub    = generator.easy_synthesize((w_ref + dw_sub   )[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "            x_iso_nm = generator.easy_synthesize((w_ref + dw_iso_nm)[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "            x_iso_dp = generator.easy_synthesize((w_ref + dw_iso_dp)[np.newaxis,:], **synthesis_kwargs)['image'][0]\n",
        "\n",
        "            # Metrics (attack, leakage, identity SSIM, 1-SSIM)\n",
        "            def mpack(x):\n",
        "                a = attack_success(x)\n",
        "                l = leakage(x)\n",
        "                i = identity_ssim(x_ref, x)\n",
        "                p = perceptual_1mssim(x_ref, x)\n",
        "                return (a, l, i, p)\n",
        "\n",
        "            stats_sub.append(mpack(x_sub))\n",
        "            stats_iso_nm.append(mpack(x_iso_nm))\n",
        "            stats_iso_dp.append(mpack(x_iso_dp))\n",
        "\n",
        "            if (ksample+1) % max(1, K//4) == 0:\n",
        "                print(f\"  progress {ksample+1}/{K}\")\n",
        "\n",
        "        def agg(arr):\n",
        "            A = np.array(arr, dtype=float)\n",
        "            return np.nanmean(A, axis=0), np.nanstd(A, axis=0)\n",
        "\n",
        "        m_sub,    s_sub    = agg(stats_sub)\n",
        "        m_iso_nm, s_iso_nm = agg(stats_iso_nm)\n",
        "        m_iso_dp, s_iso_dp = agg(stats_iso_dp)\n",
        "\n",
        "        with open(csv_path, 'a') as f:\n",
        "            # iso_nm (norm-matched isotropic; record Lfull_est for ref)\n",
        "            f.write(f'iso_nm,{eps},{delta},{tau},{np.linalg.norm(dw_iso_nm):.6f},{LS_COVER[tau]},{Lfull_est_safe},'\n",
        "                    f'{m_iso_nm[0]},{s_iso_nm[0]},{m_iso_nm[1]},{s_iso_nm[1]},'\n",
        "                    f'{m_iso_nm[2]},{s_iso_nm[2]},{m_iso_nm[3]},{s_iso_nm[3]},{alpha_used},{gamma_margin_val}\\n')\n",
        "            # iso_dp (DP ambient)\n",
        "            f.write(f'iso_dp,{eps},{delta},{tau},{sigma_iso_dp},{LS_COVER[tau]},{Lfull_est_safe},'\n",
        "                    f'{m_iso_dp[0]},{s_iso_dp[0]},{m_iso_dp[1]},{s_iso_dp[1]},'\n",
        "                    f'{m_iso_dp[2]},{s_iso_dp[2]},{m_iso_dp[3]},{s_iso_dp[3]},{alpha_used},{globals().get(\"SAFETY_FULL\",1.50)}\\n')\n",
        "            # sub (our mechanism; margin column stores gamma for cover)\n",
        "            f.write(f'sub,{eps},{delta},{tau},{sigma_sub},{LS_COVER[tau]},{Lfull_est_safe},'\n",
        "                    f'{m_sub[0]},{s_sub[0]},{m_sub[1]},{s_sub[1]},'\n",
        "                    f'{m_sub[2]},{s_sub[2]},{m_sub[3]},{s_sub[3]},{alpha_used},{gamma_margin_val}\\n')\n",
        "\n",
        "print(\"✅ calibrated run complete →\", out_dir)\n",
        "try:\n",
        "    files.download(csv_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped (Colab-only):\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "uJhO5WmPXAMr",
        "outputId": "ca0e71d1-55db-47a4-c8fb-65d9d61cd27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ambient] L_full_hat=0.2070  → safe=0.4936\n",
            "[CALIBRATION] per‑tau C_sub and ambient C_iso ready  (δ=1e-05)\n",
            "[τ=0.5] [ε=0.2] σ_sub=5.7961  σ_isoDP=5.9782\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=0.5] [ε=0.5] σ_sub=2.3185  σ_isoDP=2.3913\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=0.5] [ε=1.0] σ_sub=1.1592  σ_isoDP=1.1956\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=0.5] [ε=2.0] σ_sub=0.5796  σ_isoDP=0.5978\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=1.0] [ε=0.2] σ_sub=11.9563  σ_isoDP=11.9563\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=1.0] [ε=0.5] σ_sub=4.7825  σ_isoDP=4.7825\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=1.0] [ε=1.0] σ_sub=2.3913  σ_isoDP=2.3913\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "[τ=1.0] [ε=2.0] σ_sub=1.1956  σ_isoDP=1.1956\n",
            "  progress 50/200\n",
            "  progress 100/200\n",
            "  progress 150/200\n",
            "  progress 200/200\n",
            "✅ calibrated run complete → /content/results_empirical\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_82abb74d-dbcb-4809-8267-b138cffe04db\", \"summary_age_CLIPcalibrated.csv\", 5732)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make F2–F5 plots and a simple F1 grid (robust CSV loader that merges old/new schemas)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import math, glob, os, csv, numpy as np\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "raw_csv = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "norm_csv = f\"{out_dir}/summary_age_CLIPcalibrated_merged.csv\"\n",
        "\n",
        "# --- Normalize CSV: handle both 15-col (old) and 17-col (new) rows ---\n",
        "col17 = ['method','eps','delta','tau','sigma','Ls_est','Lfull_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha','margin']\n",
        "col15 = ['method','eps','delta','tau','sigma','Ls_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha']\n",
        "\n",
        "rows = []\n",
        "with open(raw_csv, newline='') as f:\n",
        "    rdr = csv.reader(f)\n",
        "    first = next(rdr, None)\n",
        "\n",
        "    # If the first row is a header, ignore it; otherwise treat it as data\n",
        "    def _ingest(r):\n",
        "        if not r:\n",
        "            return\n",
        "        if len(r) == 17:\n",
        "            rows.append(dict(zip(col17, r)))\n",
        "        elif len(r) == 15:\n",
        "            d = dict(zip(col15, r))\n",
        "            d['Lfull_est'] = ''\n",
        "            d['margin']    = ''\n",
        "            rows.append(d)\n",
        "        else:\n",
        "            # skip malformed rows\n",
        "            pass\n",
        "\n",
        "    if first and not (len(first) > 0 and first[0] == 'method'):\n",
        "        _ingest(first)\n",
        "    for r in rdr:\n",
        "        _ingest(r)\n",
        "\n",
        "# Build dataframe with unified schema\n",
        "df = pd.DataFrame(rows, columns=col17)\n",
        "\n",
        "# Cast numerics\n",
        "for c in col17:\n",
        "    if c != 'method':\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# Basic sanity: drop rows with missing eps/tau\n",
        "df = df.dropna(subset=['eps','tau'])\n",
        "df.to_csv(norm_csv, index=False)\n",
        "print(\"Normalized CSV written:\", norm_csv)\n",
        "\n",
        "# From now on, use the normalized dataframe `df`\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"Normalized CSV is empty. Re-run the Monte-Carlo cell (D) to generate results.\")\n",
        "\n",
        "# --- Plots ---\n",
        "def plot_metric(metric, ylabel, tau):\n",
        "    sub = df[(df['tau'] == tau)]\n",
        "    if sub.empty:\n",
        "        print(f\"No rows for tau={tau}\")\n",
        "        return None\n",
        "    plt.figure()\n",
        "    # legend order preference\n",
        "    order = [m for m in ['iso_dp','iso_nm','sub'] if m in sub['method'].unique()]\n",
        "    for method in order:\n",
        "        dsub = sub[sub['method'] == method].sort_values('eps')\n",
        "        if dsub.empty:\n",
        "            continue\n",
        "        y = dsub[metric].values\n",
        "        yerr = dsub[metric.replace('mean','std')].values\n",
        "        plt.errorbar(dsub['eps'], y, yerr=yerr, marker='o', label=method)\n",
        "    plt.xlabel('ε'); plt.ylabel(ylabel); plt.title(f'{ylabel} vs ε (τ={tau}, δ=1e-5)')\n",
        "    plt.legend(); plt.grid(True, alpha=0.2)\n",
        "    fn = f\"{out_dir}/{metric}_vs_eps_tau{tau}.png\"\n",
        "    plt.savefig(fn, bbox_inches='tight'); plt.close()\n",
        "    print(\"Saved\", fn)\n",
        "    return fn\n",
        "\n",
        "saved_figs = []\n",
        "for tau in sorted(df['tau'].dropna().unique()):\n",
        "    fn = plot_metric('attack_mean', 'Attack success (↓)', tau)       # F2\n",
        "    if fn: saved_figs.append(fn)\n",
        "    fn = plot_metric('leak_mean',   'Non-target leakage (↓)', tau)    # F3\n",
        "    if fn: saved_figs.append(fn)\n",
        "    fn = plot_metric('id_mean',     'Identity SSIM (↑)', tau)         # F4\n",
        "    if fn: saved_figs.append(fn)\n",
        "    # F5: Privacy vs Perceptual\n",
        "    subdf = df[df['tau']==tau]\n",
        "    if not subdf.empty:\n",
        "        plt.figure()\n",
        "        order = [m for m in ['iso_dp','iso_nm','sub'] if m in subdf['method'].unique()]\n",
        "        for method in order:\n",
        "            dmethod = subdf[subdf['method']==method]\n",
        "            if dmethod.empty:\n",
        "                continue\n",
        "            plt.scatter(1 - dmethod['attack_mean'], dmethod['perc_mean'], label=method)\n",
        "        plt.xlabel('Privacy = 1 - attack success (↑)')\n",
        "        plt.ylabel('Perceptual loss = 1 - SSIM (↓)')\n",
        "        plt.title(f'Privacy–Utility tradeoff (τ={tau}, δ=1e-5)'); plt.legend(); plt.grid(True, alpha=0.2)\n",
        "        fn = f\"{out_dir}/privacy_utility_tau{tau}.png\"\n",
        "        plt.savefig(fn, bbox_inches='tight'); plt.close(); print(\"Saved\", fn)\n",
        "        saved_figs.append(fn)\n",
        "\n",
        "# --- F1 grid (ref + iso_dp + sub), robust to float formatting ---\n",
        "def find_first_matching(path_glob):\n",
        "    g = glob.glob(path_glob)\n",
        "    return g[0] if len(g) > 0 else None\n",
        "\n",
        "rows = []\n",
        "for tau in sorted(df['tau'].unique()):\n",
        "    for eps in sorted(df['eps'].unique()):\n",
        "        sub_row    = df[(df['tau']==tau)&(df['eps']==eps)&(df['method']=='sub')]\n",
        "        isodp_row  = df[(df['tau']==tau)&(df['eps']==eps)&(df['method']=='iso_dp')]\n",
        "        if sub_row.empty or isodp_row.empty:\n",
        "            continue\n",
        "\n",
        "        # Use wildcards for sigma to avoid float-string mismatches\n",
        "        base_sub_glob    = f\"{out_dir}/age_sub_eps{eps}_del1e-05_tau{tau}_sig*_k0\"\n",
        "        base_iso_dp_glob = f\"{out_dir}/age_isoDP_eps{eps}_del1e-05_tau{tau}_sig*_k0\"\n",
        "        base_sub    = find_first_matching(base_sub_glob)\n",
        "        base_iso_dp = find_first_matching(base_iso_dp_glob)\n",
        "        if not base_sub or not base_iso_dp:\n",
        "            continue\n",
        "\n",
        "        p_ref = base_sub + \"_ref.png\"\n",
        "        p_iso = base_iso_dp + \"_iso_dp.png\"\n",
        "        p_sub = base_sub + \"_sub.png\"\n",
        "        if all(os.path.exists(p) for p in [p_ref, p_iso, p_sub]):\n",
        "            trip = [Image.open(p_ref), Image.open(p_iso), Image.open(p_sub)]\n",
        "            w = sum(im.width for im in trip); h = max(im.height for im in trip)\n",
        "            row = Image.new('RGB', (w,h))\n",
        "            x=0\n",
        "            for im in trip:\n",
        "                row.paste(im, (x,0)); x+=im.width\n",
        "            rows.append(row)\n",
        "\n",
        "if rows:\n",
        "    H = sum(r.height for r in rows); W = max(r.width for r in rows)\n",
        "    grid = Image.new('RGB', (W,H)); y=0\n",
        "    for r in rows:\n",
        "        grid.paste(r,(0,y)); y += r.height\n",
        "    grid_path = f\"{out_dir}/F1_qual_grid.png\"\n",
        "    grid.save(grid_path)\n",
        "    print(\"Saved\", grid_path)\n",
        "    saved_figs.append(grid_path)\n",
        "else:\n",
        "    print(\"F1 grid assembly skipped (no triplets found).\")\n",
        "\n",
        "# Auto-download key outputs individually (figures + grid)\n",
        "for p in saved_figs:\n",
        "    try: files.download(p)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n",
        "\n",
        "# Zip ALL results and download once (recommended)\n",
        "zip_path = '/content/results_empirical.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files_list in os.walk(out_dir):\n",
        "        for name in files_list:\n",
        "            full = os.path.join(root, name)\n",
        "            arc  = os.path.relpath(full, start=os.path.dirname(out_dir))\n",
        "            z.write(full, arcname=arc)\n",
        "print(\"Zipped:\", zip_path)\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "id": "eh10-Qp9XDKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "9265c718-2f0a-4bf9-f6b4-1edb5d508f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized CSV written: /content/results_empirical/summary_age_CLIPcalibrated_merged.csv\n",
            "Saved /content/results_empirical/attack_mean_vs_eps_tau0.5.png\n",
            "Saved /content/results_empirical/leak_mean_vs_eps_tau0.5.png\n",
            "Saved /content/results_empirical/id_mean_vs_eps_tau0.5.png\n",
            "Saved /content/results_empirical/privacy_utility_tau0.5.png\n",
            "Saved /content/results_empirical/attack_mean_vs_eps_tau1.0.png\n",
            "Saved /content/results_empirical/leak_mean_vs_eps_tau1.0.png\n",
            "Saved /content/results_empirical/id_mean_vs_eps_tau1.0.png\n",
            "Saved /content/results_empirical/privacy_utility_tau1.0.png\n",
            "F1 grid assembly skipped (no triplets found).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03b7d1dc-8fb2-4bc9-b5b3-724bb9196304\", \"attack_mean_vs_eps_tau0.5.png\", 26659)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_10aade7e-a6cb-42d9-a188-bef6d4fa93e0\", \"leak_mean_vs_eps_tau0.5.png\", 33140)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e8c67c78-f868-4961-96db-71ada3bbe3da\", \"id_mean_vs_eps_tau0.5.png\", 32920)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aca7510e-6bb4-4b19-9264-5275b20fe300\", \"privacy_utility_tau0.5.png\", 31786)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92b48614-5870-41e9-8e3f-685fe0e1c9e4\", \"attack_mean_vs_eps_tau1.0.png\", 25117)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f216183-4f40-48f4-ba5b-b5a6ac455b27\", \"leak_mean_vs_eps_tau1.0.png\", 36840)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_310c4d9f-669f-4f15-a238-ace46a570580\", \"id_mean_vs_eps_tau1.0.png\", 31947)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a49061e6-7b90-4011-931b-a0afc0a13242\", \"privacy_utility_tau1.0.png\", 30545)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped: /content/results_empirical.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c5f414e3-bb50-44ae-a57d-8974894071a0\", \"results_empirical.zip\", 225125)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== F: Equal-utility matching with LPIPS (AlexNet), using per‑tau Local‑Cover calibration =====\n",
        "!pip -q install lpips\n",
        "import lpips, torch, numpy as np, math, os, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lpips_net = lpips.LPIPS(net='alex').to(device).eval()\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _to_lpips_tensor(np_imgs):\n",
        "    \"\"\"\n",
        "    np_imgs: (B,H,W,3) uint8 or float in [0,255]\n",
        "    returns: torch float in [-1,1], shape (B,3,H,W)\n",
        "    \"\"\"\n",
        "    if np_imgs.ndim == 3:\n",
        "        np_imgs = np_imgs[None, ...]\n",
        "    arr = np_imgs.astype(np.float32) / 255.0\n",
        "    t = torch.from_numpy(arr).permute(0,3,1,2)  # B,3,H,W\n",
        "    t = t * 2.0 - 1.0\n",
        "    return t.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def lpips_mean(x_ref_np, x_batch_np):\n",
        "    \"\"\"Average LPIPS(x_batch, x_ref) over the batch.\"\"\"\n",
        "    Xr = _to_lpips_tensor(np.repeat(x_ref_np[None,...], x_batch_np.shape[0], axis=0))\n",
        "    X  = _to_lpips_tensor(x_batch_np)\n",
        "    d  = lpips_net(X, Xr)     # shape (B,1,1,1)\n",
        "    return float(d.mean().item())\n",
        "\n",
        "def clip_tau_batch(vecs, tau):\n",
        "    n = np.linalg.norm(vecs, axis=1, keepdims=True)\n",
        "    return vecs * np.minimum(1.0, tau/(n + 1e-12))\n",
        "\n",
        "def synth_from_latents(lat_batch):\n",
        "    bs = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "    imgs = []\n",
        "    for s in range(0, lat_batch.shape[0], bs):\n",
        "        chunk = lat_batch[s:s+bs]\n",
        "        im = generator.easy_synthesize(chunk, **synthesis_kwargs)['image']\n",
        "        imgs.append(im)\n",
        "    return np.concatenate(imgs, axis=0)  # (B,H,W,3)\n",
        "\n",
        "# Attack batch (same definition as D)\n",
        "y_ref = (clip_scores([x_ref])['age'][0] >= 0.0)\n",
        "def attack_success_batch(x_batch):\n",
        "    scores = clip_scores(x_batch)['age']   # shape [B]\n",
        "    preds  = (scores >= 0.0)\n",
        "    return float(np.mean((preds == y_ref).astype(np.float32)))\n",
        "\n",
        "# -----------------------------\n",
        "# Measurement routines\n",
        "# -----------------------------\n",
        "def measure_subspace(K_eval, sigma_sub, tau):\n",
        "    \"\"\"Return (lpips_mean, attack_mean) for SUB at given sigma,tau using K_eval samples.\"\"\"\n",
        "    d, k = Q.shape\n",
        "    z = np.random.normal(0.0, sigma_sub, size=(K_eval, k))\n",
        "    dw = (Q @ z.T).T\n",
        "    dw = clip_tau_batch(dw, tau)\n",
        "    lat = w_ref[None,:] + dw\n",
        "    imgs = synth_from_latents(lat)\n",
        "    lp  = lpips_mean(x_ref, imgs)\n",
        "    atk = attack_success_batch(imgs)\n",
        "    return lp, atk\n",
        "\n",
        "def measure_iso(K_eval, sigma_iso, tau):\n",
        "    \"\"\"Return (lpips_mean, attack_mean) for ISO at given sigma,tau using K_eval samples.\"\"\"\n",
        "    d = Q.shape[0]\n",
        "    z = np.random.normal(0.0, sigma_iso, size=(K_eval, d))\n",
        "    z = clip_tau_batch(z, tau)\n",
        "    lat = w_ref[None,:] + z\n",
        "    imgs = synth_from_latents(lat)\n",
        "    lp  = lpips_mean(x_ref, imgs)\n",
        "    atk = attack_success_batch(imgs)\n",
        "    return lp, atk\n",
        "\n",
        "def tune_sigma_iso_to_match_lpips(tau, lp_target, sigma_init, K_lp=64, iters=7, tol=2e-3):\n",
        "    \"\"\"\n",
        "    Binary-search sigma_iso so ISO LPIPS ≈ lp_target.\n",
        "    Start bracket around sigma_init; widen if needed.\n",
        "    \"\"\"\n",
        "    lo, hi = sigma_init * 0.25, sigma_init * 4.0\n",
        "    # ensure bracket covers target (expand up to a few times)\n",
        "    lp_lo, _ = measure_iso(max(32, K_lp//2), lo, tau)\n",
        "    lp_hi, _ = measure_iso(max(32, K_lp//2), hi, tau)\n",
        "    expand = 0\n",
        "    while not (lp_lo <= lp_target <= lp_hi) and expand < 3:\n",
        "        lo *= 0.5; hi *= 2.0\n",
        "        lp_lo, _ = measure_iso(max(32, K_lp//2), lo, tau)\n",
        "        lp_hi, _ = measure_iso(max(32, K_lp//2), hi, tau)\n",
        "        expand += 1\n",
        "\n",
        "    sigma = sigma_init\n",
        "    for _ in range(iters):\n",
        "        mid = 0.5 * (lo + hi)\n",
        "        lp_mid, _ = measure_iso(K_lp, mid, tau)\n",
        "        if lp_mid < lp_target - tol:\n",
        "            lo = mid\n",
        "        elif lp_mid > lp_target + tol:\n",
        "            hi = mid\n",
        "        else:\n",
        "            sigma = mid\n",
        "            break\n",
        "        sigma = mid\n",
        "    return sigma\n",
        "\n",
        "# -----------------------------\n",
        "# Per‑tau calibration constants\n",
        "# -----------------------------\n",
        "if 'LS_COVER' not in globals() or len(LS_COVER)==0:\n",
        "    raise RuntimeError(\"LS_COVER not found. Run the Local‑Cover block (C‑LC) before F.\")\n",
        "sqrt_term = math.sqrt(2.0 * math.log(1.25 / 1e-5))  # δ fixed here\n",
        "C_SUB_BY_TAU = {tau: LS_COVER[tau] * sqrt_term for tau in LS_COVER}\n",
        "\n",
        "# Ambient constant for ISO_DP (estimate if missing)\n",
        "if 'Lfull_est_safe' not in globals():\n",
        "    # quick ambient estimate using the helper from D\n",
        "    def clip_age_gender_vector(np_batch):\n",
        "        s = clip_scores(np_batch)\n",
        "        return np.stack([s['age'], s['gender']], axis=1)\n",
        "    def estimate_Lfull_ambient_cdiff(w_ref, h=0.05, num_dirs=128, seed=7, scorer_fn=clip_age_gender_vector):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        d = w_ref.shape[0]\n",
        "        dirs = rng.normal(size=(num_dirs, d))\n",
        "        dirs /= (np.linalg.norm(dirs, axis=1, keepdims=True) + 1e-12)\n",
        "        bs_default = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "        deriv_all = []\n",
        "        for s0 in range(0, num_dirs, bs_default):\n",
        "            v = dirs[s0:s0+bs_default]\n",
        "            lat_plus  = w_ref[None,:] + h * v\n",
        "            lat_minus = w_ref[None,:] - h * v\n",
        "            imgs_p = generator.easy_synthesize(lat_plus,  **synthesis_kwargs)['image']\n",
        "            imgs_m = generator.easy_synthesize(lat_minus, **synthesis_kwargs)['image']\n",
        "            s_p = np.asarray(scorer_fn(imgs_p))\n",
        "            s_m = np.asarray(scorer_fn(imgs_m))\n",
        "            if s_p.ndim == 1:\n",
        "                deriv_blk = np.abs(s_p - s_m) / (2*h)\n",
        "            else:\n",
        "                deriv_blk = np.linalg.norm(s_p - s_m, axis=-1) / (2*h)\n",
        "            deriv_all.append(deriv_blk)\n",
        "        deriv = np.concatenate(deriv_all, axis=0)\n",
        "        return float(np.max(deriv)), deriv\n",
        "    Lfull_hat, _ = estimate_Lfull_ambient_cdiff(w_ref, h=0.05, num_dirs=128, seed=7)\n",
        "    SAFETY_FULL  = globals().get('SAFETY_FULL', 1.50)\n",
        "    Lfull_est_safe = max(Lfull_hat * SAFETY_FULL, max(LS_COVER.values()))\n",
        "C_ISO = Lfull_est_safe * sqrt_term\n",
        "\n",
        "# -----------------------------\n",
        "# Equal‑utility CSV + run\n",
        "# -----------------------------\n",
        "eq_csv = f\"{out_dir}/summary_equalUtility.csv\"\n",
        "if not os.path.exists(eq_csv):\n",
        "    with open(eq_csv, 'w') as f:\n",
        "        f.write('tau,eps_sub,sigma_sub,lpips_sub,attack_sub,'\n",
        "                'sigma_iso_match,lpips_iso_match,attack_iso_match,'\n",
        "                'eps_iso_implied\\n')\n",
        "\n",
        "K_lp   = 64    # samples to measure LPIPS in tuning\n",
        "K_eval = 128   # samples to measure final attack at the matched LPIPS\n",
        "\n",
        "for tau in tau_list:\n",
        "    Ls_safe_tau = LS_COVER[tau]\n",
        "    C_sub_tau   = Ls_safe_tau * sqrt_term\n",
        "    rows_print = []\n",
        "    for eps in eps_list:\n",
        "        # Subspace σ from Local‑Cover DP‑style calibration\n",
        "        sigma_sub = (C_sub_tau * tau) / eps\n",
        "\n",
        "        # Measure SUB LPIPS and attack\n",
        "        lp_sub, atk_sub = measure_subspace(K_lp, sigma_sub, tau)\n",
        "\n",
        "        # ISO_DP starting point; then tune to match LPIPS\n",
        "        sigma_iso_dp = (C_ISO * tau) / eps\n",
        "        sigma_iso_match = tune_sigma_iso_to_match_lpips(tau, lp_sub, sigma_iso_dp, K_lp=K_lp)\n",
        "        lp_iso, atk_iso = measure_iso(K_eval, sigma_iso_match, tau)\n",
        "\n",
        "        # Implied epsilon for the matched ISO point (under ambient constant)\n",
        "        eps_iso_implied = (C_ISO * tau / sigma_iso_match)\n",
        "\n",
        "        with open(eq_csv, 'a') as f:\n",
        "            f.write(f'{tau},{eps},{sigma_sub},{lp_sub},{atk_sub},'\n",
        "                    f'{sigma_iso_match},{lp_iso},{atk_iso},{eps_iso_implied}\\n')\n",
        "\n",
        "        rows_print.append((eps, lp_sub, atk_sub, lp_iso, atk_iso, sigma_iso_match, eps_iso_implied))\n",
        "\n",
        "    # Pretty print per‑τ summary\n",
        "    print(f\"\\n[Equal-utility @ τ={tau}]  (LPIPS matched to SUB)\")\n",
        "    print(\"eps_sub |  LPIPS  SUB  | Attack SUB |  LPIPS  ISO  | Attack ISO |  σ_iso_match  |  eps_iso_implied\")\n",
        "    for (eps, lp_s, a_s, lp_i, a_i, s_iso, e_iso) in rows_print:\n",
        "        print(f\"{eps:6.2f} |  {lp_s:10.4f} |   {a_s:9.3f} |  {lp_i:10.4f} |   {a_i:9.3f} |  {s_iso:12.4f} |  {e_iso:14.4f}\")\n",
        "\n",
        "# Auto-download CSV (Colab)\n",
        "try:\n",
        "    files.download(eq_csv)\n",
        "except Exception as e:\n",
        "    print(\"Download skipped:\", e)\n",
        "\n",
        "# -------- Plot: Attack at matched LPIPS (per τ) --------\n",
        "eq = pd.read_csv(eq_csv)\n",
        "for tau in sorted(eq['tau'].unique()):\n",
        "    sub = eq[eq['tau']==tau].sort_values('eps_sub')\n",
        "    plt.figure()\n",
        "    plt.plot(sub['eps_sub'], sub['attack_sub'], marker='o', label='sub (LPIPS target)')\n",
        "    plt.plot(sub['eps_sub'], sub['attack_iso_match'], marker='s', label='iso (LPIPS matched)')\n",
        "    plt.xlabel('ε (of SUB point)'); plt.ylabel('Attack success (↓)')\n",
        "    plt.title(f'Attack @ matched LPIPS (τ={tau})')\n",
        "    plt.grid(True, alpha=0.2); plt.legend()\n",
        "    fig_path = f\"{out_dir}/F5_equal_utility_tau{tau}.png\"\n",
        "    plt.savefig(fig_path, bbox_inches='tight'); plt.close()\n",
        "    print(\"Saved\", fig_path)\n",
        "    try: files.download(fig_path)\n",
        "    except Exception as e: print(\"Download skipped:\", e)\n"
      ],
      "metadata": {
        "id": "ha1Z7-OKCvGZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "9abc72e3-a370-4769-c447-b9bf4472f63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 232MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "\n",
            "[Equal-utility @ τ=0.5]  (LPIPS matched to SUB)\n",
            "eps_sub |  LPIPS  SUB  | Attack SUB |  LPIPS  ISO  | Attack ISO |  σ_iso_match  |  eps_iso_implied\n",
            "  0.20 |      0.0254 |       0.984 |      0.0147 |       1.000 |      189.8083 |          0.0063\n",
            "  0.50 |      0.0248 |       1.000 |      0.0150 |       1.000 |       75.9233 |          0.0157\n",
            "  1.00 |      0.0206 |       1.000 |      0.0151 |       1.000 |       37.9617 |          0.0315\n",
            "  2.00 |      0.0168 |       1.000 |      0.0153 |       1.000 |       16.7412 |          0.0714\n",
            "\n",
            "[Equal-utility @ τ=1.0]  (LPIPS matched to SUB)\n",
            "eps_sub |  LPIPS  SUB  | Attack SUB |  LPIPS  ISO  | Attack ISO |  σ_iso_match  |  eps_iso_implied\n",
            "  0.20 |      0.0726 |       0.969 |      0.0438 |       1.000 |      379.6165 |          0.0063\n",
            "  0.50 |      0.0702 |       0.969 |      0.0448 |       1.000 |      151.8466 |          0.0157\n",
            "  1.00 |      0.0582 |       0.953 |      0.0436 |       1.000 |       75.9233 |          0.0315\n",
            "  2.00 |      0.0449 |       0.984 |      0.0421 |       1.000 |       19.1488 |          0.1249\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_430b8973-3ae4-4ddd-bb1b-c33719084375\", \"summary_equalUtility.csv\", 1047)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/results_empirical/F5_equal_utility_tau0.5.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60ffbb62-6d14-49e8-9dd4-325225526bb1\", \"F5_equal_utility_tau0.5.png\", 36121)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/results_empirical/F5_equal_utility_tau1.0.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_714a4c8e-fe73-4284-bbf8-a8e86fdea171\", \"F5_equal_utility_tau1.0.png\", 34861)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === OPTIONAL: Verification (calibration, mechanism, win-rates, latent leakage) ===\n",
        "import math, numpy as np, pandas as pd, csv, os\n",
        "\n",
        "csv_path = f\"{out_dir}/summary_age_CLIPcalibrated.csv\"\n",
        "\n",
        "# --- Normalize CSV: accept both 15-col (old) and 17-col (new) formats ---\n",
        "col17 = ['method','eps','delta','tau','sigma','Ls_est','Lfull_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha','margin']\n",
        "col15 = ['method','eps','delta','tau','sigma','Ls_est',\n",
        "         'attack_mean','attack_std','leak_mean','leak_std',\n",
        "         'id_mean','id_std','perc_mean','perc_std','alpha']\n",
        "\n",
        "def load_normalized(csv_path):\n",
        "    rows = []\n",
        "    with open(csv_path, newline='') as f:\n",
        "        rdr = csv.reader(f)\n",
        "        first = next(rdr, None)\n",
        "\n",
        "        def ingest(r):\n",
        "            if not r:\n",
        "                return\n",
        "            # skip header line if present\n",
        "            if r[0] == 'method':\n",
        "                return\n",
        "            if len(r) == 17:\n",
        "                rows.append(dict(zip(col17, r)))\n",
        "            elif len(r) == 15:\n",
        "                d = dict(zip(col15, r))\n",
        "                d['Lfull_est'] = ''\n",
        "                d['margin']    = ''\n",
        "                rows.append(d)\n",
        "            else:\n",
        "                # malformed row length → skip\n",
        "                return\n",
        "\n",
        "        # If the first line is data (not header), ingest it\n",
        "        if first and first[0] != 'method':\n",
        "            ingest(first)\n",
        "        for r in rdr:\n",
        "            ingest(r)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=col17)\n",
        "    # cast numerics (leave 'method' as string)\n",
        "    for c in col17:\n",
        "        if c != 'method':\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "    # drop rows with missing eps/tau\n",
        "    df = df.dropna(subset=['eps','tau'])\n",
        "    return df\n",
        "\n",
        "dfv = load_normalized(csv_path)\n",
        "print(\"Rows:\", len(dfv))\n",
        "print(\"Methods present:\", sorted(dfv['method'].dropna().unique()))\n",
        "\n",
        "# --- Calibration constants (robust) ---\n",
        "def _get_global(name, default=np.nan):\n",
        "    return globals()[name] if name in globals() else default\n",
        "\n",
        "delta_val = _get_global('delta', 1e-5)\n",
        "Ls_safe   = _get_global('Ls_est_safe', np.nan)     # subspace L_S (with safety)\n",
        "Lf_safe   = _get_global('Lfull_est_safe', np.nan)  # ambient L (with safety), optional\n",
        "\n",
        "# Fallback from CSV if not defined in this session\n",
        "if (not np.isfinite(Ls_safe)) and 'Ls_est' in dfv.columns and dfv['Ls_est'].notna().any():\n",
        "    # prefer 'sub' rows for Ls_est\n",
        "    tmp = dfv[dfv['method']=='sub']['Ls_est'].dropna()\n",
        "    if tmp.shape[0] == 0:\n",
        "        tmp = dfv['Ls_est'].dropna()\n",
        "    if tmp.shape[0] > 0:\n",
        "        Ls_safe = float(tmp.iloc[0])\n",
        "\n",
        "if (not np.isfinite(Lf_safe)) and 'Lfull_est' in dfv.columns and dfv['Lfull_est'].notna().any():\n",
        "    # prefer iso_dp rows for Lfull_est, else any available\n",
        "    tmp = dfv[dfv['method']=='iso_dp']['Lfull_est'].dropna()\n",
        "    if tmp.shape[0] == 0:\n",
        "        tmp = dfv['Lfull_est'].dropna()\n",
        "    if tmp.shape[0] > 0:\n",
        "        Lf_safe = float(tmp.iloc[0])\n",
        "\n",
        "def _calib_const(Lsafe):\n",
        "    return (Lsafe * math.sqrt(2.0 * math.log(1.25/delta_val))) if np.isfinite(Lsafe) else float('nan')\n",
        "\n",
        "C_sub = _calib_const(Ls_safe)\n",
        "C_iso = _calib_const(Lf_safe)\n",
        "print(f\"[calibration] C_sub={C_sub:.4f}  C_iso={C_iso:.4f}  (δ={delta_val})\")\n",
        "\n",
        "# --- Mechanism audit (subspace projection + clipping) ---\n",
        "b = int(max(1, getattr(generator, 'batch_size', 4)))\n",
        "tau = 0.5; eps = 0.5\n",
        "sigma_sub = (Ls_safe * tau * math.sqrt(2.0 * math.log(1.25/delta_val))) / eps\n",
        "d, k = Q.shape\n",
        "\n",
        "z = np.random.normal(0.0, sigma_sub, size=(b, k))\n",
        "dw_sub = (Q @ z.T).T\n",
        "# projection residual\n",
        "proj = (Q @ (Q.T @ dw_sub.T)).T\n",
        "residual = np.linalg.norm(dw_sub - proj, axis=1) / (np.linalg.norm(dw_sub, axis=1) + 1e-12)\n",
        "\n",
        "def clip_tau_batch(vecs, tau):\n",
        "    n = np.linalg.norm(vecs, axis=1, keepdims=True)\n",
        "    return vecs * np.minimum(1.0, tau/(n+1e-12))\n",
        "\n",
        "dw_sub_c = clip_tau_batch(dw_sub, tau)\n",
        "norms = np.linalg.norm(dw_sub_c, axis=1)\n",
        "print(f\"[audit] subspace residual (median, max): {np.median(residual):.2e}, {np.max(residual):.2e}\")\n",
        "print(f\"[audit] clip ||Δw_sub|| ≤ τ ? max norm = {norms.max():.4f}  (τ={tau})\")\n",
        "\n",
        "# --- Win-rate summary: sub vs best available isotropic baseline ---\n",
        "def choose_baseline(methods):\n",
        "    if 'iso_dp' in methods: return 'iso_dp'\n",
        "    if 'iso'    in methods: return 'iso'\n",
        "    if 'iso_nm' in methods: return 'iso_nm'\n",
        "    return None\n",
        "\n",
        "baseline = choose_baseline(set(dfv['method'].dropna().unique()))\n",
        "if baseline is None:\n",
        "    print(\"No isotropic baseline found (iso_dp / iso / iso_nm); skipping win-rate summary.\")\n",
        "else:\n",
        "    def win_rate(df, metric, better='lower', m1='sub', m2=baseline):\n",
        "        pivot = df.pivot_table(index=['tau','eps'], columns='method', values=f'{metric}_mean')\n",
        "        # keep only rows where both methods exist\n",
        "        cols = [c for c in [m1, m2] if c in pivot.columns]\n",
        "        if len(cols) < 2:\n",
        "            return 0, 0\n",
        "        pivot = pivot.dropna(subset=cols, how='any')\n",
        "        if pivot.empty:\n",
        "            return 0, 0\n",
        "        if better == 'lower':\n",
        "            wins = (pivot[m1] < pivot[m2]).sum()\n",
        "        else:\n",
        "            wins = (pivot[m1] > pivot[m2]).sum()\n",
        "        return int(wins), int(pivot.shape[0])\n",
        "\n",
        "    for metr, better in [('attack','lower'), ('leak','lower'), ('id','higher')]:\n",
        "        w, t = win_rate(dfv, metr, better, 'sub', baseline)\n",
        "        print(f\"{metr} ({'↓' if better=='lower' else '↑'})  sub better than {baseline} in {w}/{t} budgets\")\n",
        "\n",
        "    # Perceptual gap (keep utility similar)\n",
        "    pivot_pq = dfv.pivot_table(index=['tau','eps'], columns='method', values='perc_mean')\n",
        "    if ('sub' in pivot_pq.columns) and (baseline in pivot_pq.columns):\n",
        "        rel_gap = (pivot_pq['sub'] - pivot_pq[baseline]).abs().mean()\n",
        "        print(f\"mean |Δ(perceptual)| between sub and {baseline}: {float(rel_gap):.4f}\")\n",
        "    else:\n",
        "        print(\"Perceptual comparison skipped (columns missing).\")\n",
        "\n",
        "# --- Latent leakage sanity (gender direction) ---\n",
        "Kcheck = 200\n",
        "z = np.random.normal(0.0, sigma_sub, size=(Kcheck, k))\n",
        "dw_sub = (Q @ z.T).T\n",
        "dw_sub = clip_tau_batch(dw_sub, tau)\n",
        "\n",
        "u = np.random.normal(0.0, 1.0, size=(Kcheck, d))\n",
        "u /= (np.linalg.norm(u, axis=1, keepdims=True) + 1e-12)\n",
        "dw_nm = u * (np.linalg.norm(dw_sub, axis=1, keepdims=True) + 1e-12)\n",
        "dw_nm = clip_tau_batch(dw_nm, tau)\n",
        "\n",
        "print(\"latent leakage |Δw·b_gender|  mean(sub), mean(iso_nm):\",\n",
        "      float(np.mean(np.abs(dw_sub @ b_gender))),\n",
        "      float(np.mean(np.abs(dw_nm  @ b_gender))))\n"
      ],
      "metadata": {
        "id": "a7LmiwFO-7VM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7ff50f-5dcc-4733-9479-791e23333d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 24\n",
            "Methods present: ['iso_dp', 'iso_nm', 'sub']\n",
            "[calibration] C_sub=2.3185  C_iso=2.3913  (δ=1e-05)\n",
            "[audit] subspace residual (median, max): 2.26e-16, 3.46e-16\n",
            "[audit] clip ||Δw_sub|| ≤ τ ? max norm = 0.5000  (τ=0.5)\n",
            "attack (↓)  sub better than iso_dp in 6/8 budgets\n",
            "leak (↓)  sub better than iso_dp in 0/8 budgets\n",
            "id (↑)  sub better than iso_dp in 0/8 budgets\n",
            "mean |Δ(perceptual)| between sub and iso_dp: 0.0089\n",
            "latent leakage |Δw·b_gender|  mean(sub), mean(iso_nm): 6.561969856513439e-14 0.015995824221490502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Compact F1 grids for IEEE (one-column width) ===\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os, math, numpy as np, pandas as pd\n",
        "\n",
        "df = pd.read_csv(f\"{out_dir}/summary_age_CLIPcalibrated.csv\")\n",
        "\n",
        "# Where the triplets are saved (from your Monte-Carlo block naming)\n",
        "def triplet_paths(tau, eps, sigma_sub, sigma_iso_dp):\n",
        "    base_sub    = f\"{out_dir}/age_sub_eps{eps}_del1e-05_tau{tau}_sig{round(sigma_sub,4)}_k0\"\n",
        "    base_iso_dp = f\"{out_dir}/age_isoDP_eps{eps}_del1e-05_tau{tau}_sig{round(sigma_iso_dp,4)}_k0\"\n",
        "    return {\n",
        "        'ref': base_sub + \"_ref.png\",\n",
        "        'iso': base_iso_dp + \"_iso_dp.png\",\n",
        "        'sub': base_sub + \"_sub.png\"\n",
        "    }\n",
        "\n",
        "def safe_open(path):\n",
        "    return Image.open(path).convert(\"RGB\") if os.path.exists(path) else None\n",
        "\n",
        "def draw_label(img, text, bar_h=18):\n",
        "    w,h = img.size\n",
        "    bar = Image.new('RGB', (w, bar_h), (255,255,255))\n",
        "    im2 = Image.new('RGB', (w, h+bar_h), (255,255,255))\n",
        "    im2.paste(img, (0,0)); im2.paste(bar, (0,h))\n",
        "    d = ImageDraw.Draw(im2)\n",
        "    d.text((6, h+2), text, fill=(0,0,0))\n",
        "    return im2\n",
        "\n",
        "def build_f1_for_tau(tau, eps_show=(0.2,0.5,1.0,2.0),\n",
        "                     cell=128, pad=6, column_width_px=1050, font_note=True):\n",
        "    # gather per-ε sigmas\n",
        "    row_sub = df[(df['tau']==tau)&(df['method']=='sub')].set_index('eps')\n",
        "    row_iso = df[(df['tau']==tau)&(df['method']=='iso_dp')].set_index('eps')\n",
        "    cols = []\n",
        "    for eps in eps_show:\n",
        "        if eps not in row_sub.index or eps not in row_iso.index:\n",
        "            continue\n",
        "        sig_sub = row_sub.loc[eps, 'sigma']\n",
        "        sig_iso = row_iso.loc[eps, 'sigma']\n",
        "        paths = triplet_paths(tau, eps, sig_sub, sig_iso)\n",
        "        ref = safe_open(paths['ref']); iso = safe_open(paths['iso']); sub = safe_open(paths['sub'])\n",
        "        if not (ref and iso and sub):\n",
        "            continue\n",
        "        # thumbnail to cell size (square)\n",
        "        ref = ref.resize((cell,cell), Image.BICUBIC)\n",
        "        iso = iso.resize((cell,cell), Image.BICUBIC)\n",
        "        sub = sub.resize((cell,cell), Image.BICUBIC)\n",
        "        # label with (ε,σ_sub)\n",
        "        lab = f\"ε={eps:g}, σ_sub={sig_sub:.2f}\"\n",
        "        ref = draw_label(ref, lab)\n",
        "        iso = draw_label(iso, \"Iso-DP\")\n",
        "        sub = draw_label(sub, \"Subspace\")\n",
        "        # stack 3 rows (Ref, Iso, Sub) into one column\n",
        "        col_h = ref.size[1] + iso.size[1] + sub.size[1] + 2*pad\n",
        "        col   = Image.new('RGB', (cell, col_h), (255,255,255))\n",
        "        y=0\n",
        "        for im in [ref, iso, sub]:\n",
        "            col.paste(im, (0,y)); y += im.size[1] + pad\n",
        "        cols.append(col)\n",
        "\n",
        "    if not cols:\n",
        "        print(f\"[F1] No triplets found for τ={tau}\")\n",
        "        return None\n",
        "\n",
        "    # concat columns with padding\n",
        "    w_each = cols[0].size[0]\n",
        "    h_max  = max(c.size[1] for c in cols)\n",
        "    W = len(cols)*w_each + (len(cols)-1)*pad\n",
        "    H = h_max\n",
        "    grid = Image.new('RGB', (W,H), (255,255,255))\n",
        "    x=0\n",
        "    for c in cols:\n",
        "        # vertical center each column\n",
        "        y0 = (H - c.size[1])//2\n",
        "        grid.paste(c, (x,y0))\n",
        "        x += w_each + pad\n",
        "\n",
        "    # scale to IEEE 1-column width\n",
        "    if W > column_width_px:\n",
        "        new_h = int(H * (column_width_px / W))\n",
        "        grid = grid.resize((column_width_px, new_h), Image.BICUBIC)\n",
        "\n",
        "    outp = f\"{out_dir}/F1_qual_grid_tau{tau}_ieee.png\"\n",
        "    grid.save(outp, optimize=True, quality=95)\n",
        "    print(\"Saved\", outp)\n",
        "    return outp\n",
        "\n",
        "# build for both τ=0.5 and τ=1.0\n",
        "g1 = build_f1_for_tau(0.5)\n",
        "g2 = build_f1_for_tau(1.0)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    for p in [g1,g2]:\n",
        "        if p: files.download(p)\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "print(\"For LaTeX (IEEEtran):\")\n",
        "print(r\"\"\"\\begin{figure}[t]\n",
        "  \\centering\n",
        "  \\includegraphics[width=\\columnwidth]{results_empirical/F1_qual_grid_tau0.5_ieee}\n",
        "  \\caption{Qualitative comparison at $\\tau{=}0.5$. Columns: $\\epsilon\\in\\{0.2,0.5,1.0,2.0\\}$ (labeled with $\\sigma_{\\text{sub}}$). Rows: reference, Iso-DP, Subspace.}\n",
        "\\end{figure}\"\"\")\n"
      ],
      "metadata": {
        "id": "6d3VOcGyMaoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320826ad-5baa-405f-ed24-2d1507955a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] No triplets found for τ=0.5\n",
            "[F1] No triplets found for τ=1.0\n",
            "For LaTeX (IEEEtran):\n",
            "\\begin{figure}[t]\n",
            "  \\centering\n",
            "  \\includegraphics[width=\\columnwidth]{results_empirical/F1_qual_grid_tau0.5_ieee}\n",
            "  \\caption{Qualitative comparison at $\\tau{=}0.5$. Columns: $\\epsilon\\in\\{0.2,0.5,1.0,2.0\\}$ (labeled with $\\sigma_{\\text{sub}}$). Rows: reference, Iso-DP, Subspace.}\n",
            "\\end{figure}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99426144dbe648a29aa21e29c90ef190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_147a3cdad079466a83890425f5f1137d",
              "IPY_MODEL_f521c60fc86c4d91a273ec59ba52168c",
              "IPY_MODEL_d49b0833fc9647b987a49617bfe610e6"
            ],
            "layout": "IPY_MODEL_81f437e6e2114b6395a0f21fcfb1bbe3"
          }
        },
        "147a3cdad079466a83890425f5f1137d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb33a1867cb40c198a6384e451a0eda",
            "placeholder": "​",
            "style": "IPY_MODEL_865a18cc307041318a1313f0eb2565c0",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "f521c60fc86c4d91a273ec59ba52168c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a59f45b70b346c2b97d331325cb0fbe",
            "max": 598516980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11025bd118d840979a309d9119d8164a",
            "value": 598516980
          }
        },
        "d49b0833fc9647b987a49617bfe610e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e5c9e49ca54dd0bc75e10433f9f1ea",
            "placeholder": "​",
            "style": "IPY_MODEL_19056f5cfcbb43beb4c27ce72dd15abc",
            "value": " 599M/599M [00:02&lt;00:00, 510MB/s]"
          }
        },
        "81f437e6e2114b6395a0f21fcfb1bbe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb33a1867cb40c198a6384e451a0eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865a18cc307041318a1313f0eb2565c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a59f45b70b346c2b97d331325cb0fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11025bd118d840979a309d9119d8164a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7e5c9e49ca54dd0bc75e10433f9f1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19056f5cfcbb43beb4c27ce72dd15abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}